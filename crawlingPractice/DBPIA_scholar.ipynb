{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library import\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "browser = webdriver.Chrome()\n",
    "\n",
    "\n",
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98'\n",
    "browser.get(url)\n",
    "time.sleep(1)\n",
    "pages = browser.find_element(By.ID,\"pageList\")\n",
    "\n",
    "page_list = pages.find_elements(By.TAG_NAME,'a')\n",
    "\n",
    "title = []\n",
    "content = []\n",
    "writer = []\n",
    "detail_url_list = []\n",
    "\n",
    "# 페이지 마다 링크 가져오기\n",
    "for p in range(3):\n",
    "    page_list = pages.find_elements(By.TAG_NAME,'a')\n",
    "    page_list[p].send_keys(Keys.ENTER)\n",
    "    time.sleep(1)\n",
    "    datas = browser.find_elements(By.CLASS_NAME,'thesis__link')\n",
    "    for i in datas:\n",
    "        detail_url = i.get_attribute('href')\n",
    "        detail_url_list.append(detail_url)\n",
    "\n",
    "# 가져온 링크로 제목, 초안 만들기\n",
    "for i in detail_url_list:\n",
    "    browser.get(i)\n",
    "    title.append(browser.find_element(By.ID,'thesisTitle').text)\n",
    "    try:\n",
    "        content.append(browser.find_element(By.CLASS_NAME,'abstractTxt').text)\n",
    "    except:\n",
    "        content.append(\"no element.\")\n",
    "        continue\n",
    "\n",
    "# 총 출력\n",
    "for i in range(len(detail_url_list)):\n",
    "    print(title[i])\n",
    "    print(content[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.dbpia.co.kr/'\n",
    "browser.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1357463533.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    browser.find_element(By.ID,\"searchInput\").\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "browser.find_element(By.ID,'serchInput').click()\n",
    "time.sleep(1)\n",
    "browser.find_element(By.ID,\"searchInput\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98'\n",
    "browser.get(url)\n",
    "page_list = browser.find_element(By.ID,\"pageList\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11288233',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11232110',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11231265',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11342490',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230368',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11287945',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11287925',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11229995',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11266669',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11229993',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230542',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11225164',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230002',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11219157',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11218630',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11217717',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11230125',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11214681',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11217524',\n",
       " 'https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11219099']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# url = browser.find_element(By.CLASS_NAME,'thesis__link').get_attribute('href')\n",
    "\n",
    "datas = browser.find_elements(By.CLASS_NAME,'thesis__link')\n",
    "detail_url_list = []\n",
    "title = []\n",
    "content = []\n",
    "writer = []\n",
    "\n",
    "for i in datas:\n",
    "    detail_url = i.get_attribute('href')\n",
    "    detail_url_list.append(detail_url)\n",
    "\n",
    "\n",
    "detail_url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in detail_url_list:\n",
    "    browser.get(i)\n",
    "    title.append(browser.find_element(By.ID,'thesisTitle').text)\n",
    "    try:\n",
    "        content.append(browser.find_element(By.CLASS_NAME,'abstractTxt').text)\n",
    "    except:\n",
    "        content.append(\"no element.\")\n",
    "        continue\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "플랫폼노동의 알고리즘 현황과 대응방안 – 알고리즘의 공정성과 투명성, 노동자 통제를 중심으로\n",
      "no element.\n",
      "\n",
      "선박 추진용 2행정 저속엔진의 고장모드 데이터 개발 및 LSTM 알고리즘을 활용한 특성인자 신뢰성 검증연구\n",
      "In the 4th industrial revolution, changes in the technological paradigm have had a direct impact on the maintenance system of ships. The 2-stroke low speed engine system integrates with the core equipment required for propulsive power. The Condition Based Management (CBM) is defined as a technology that predictive maintenance methods in existing calender-based or running time based maintenance systems by monitoring the condition of machinery and diagnosis/prognosis failures. In this study, we have established a framework for CBM technology development on our own, and are engaged in engineering-based failure analysis, data development and management, data feature analysis and pre-processing, and verified the reliability of failure mode DB using LSTM algorithms. We developed various simulated failure mode scenarios for 2-stroke low speed engine and researched to produce data on onshore basis test_beds. The analysis and pre-processing of normal and abnormal status data acquired through failure mode simulation experiment used various Exploratory Data Analysis (EDA) techniques to feature extract not only data on the performance and efficiency of 2-stroke low speed engine but also key feature data using multivariate statistical analysis. In addition, by developing an LSTM classification algorithm, we tried to verify the reliability of various failure mode data with time-series characteristics.\n",
      "\n",
      "시분할 다중 접속 기반 무선 메쉬 네트워크에서 브로드캐스트 스케줄링 문제를 위한 타부서치 알고리즘\n",
      "시분할 다중 접속 기반에서 브로드캐스트 스케줄링 문제는 타임 슬롯을 사용하여 모든 단말이 충돌 없이 전송할 수 있도록 설계하는 문제이다. 본 논문에서는 시분할 다중 접속 기반의 무선 메쉬 네트워크에서 브로드캐스트를 사용하는 노드의 전송 스케줄을 최적화하여 전체 전송 횟수와 타임 슬롯 이용률을 최대화하는 브로드캐스트 스케줄링 최적화 알고리즘을 제안한다. 제안된 최적화 알고리즘은 메타휴리스틱 방식 중 하나인 타부서치 알고리즘을 사용한다. 제안된 타부서치 알고리즘은 전체 전송 횟수를 최대화하는 목적함수를 사용하여 효율적인 이웃해 생성방식을 설계하였다. 본 논문에서는 네트워크에서 발생하는 모든 브로드캐스팅에 대하여 전체 전송 횟수와 타임 슬롯 이용률 관점에서 제안된 타부서치 알고리즘의 성능평가를 수행하였다. 성능평가 결과에서 제안된 타부서치 알고리즘은 이전에 제안된 다른 최적화 알고리즘보다 더 우수한 결과를 나타내었다.\n",
      "\n",
      "The broadcast scheduling problem based in the time division multiple access is a problem of designing that all nodes can transmit without collision using time slots. In this paper, we propose a broadcast scheduling optimization algorithm that maximizes the total number of transmissions and channel utilization by optimizing the transmission schedule of a node using broadcast in TDMA-based wireless mesh networks. The proposed optimization algorithm uses Tabu search as one of metaheuristic methods. The proposed Tabu search algorithm was used as an objective function to maximize the total number of transmissions, and the neighborhood generation method was efficiently designed. In this paper, performance evaluation of the proposed tabu search algorithm was performed in terms of the total number of transmissions and time slot utilization for all broadcasting occurring in the network. In the performance evaluation results, the proposed tabu search algorithm showed better results than other previously proposed optimization algorithms.\n",
      "\n",
      "EM 알고리즘을 이용한 기계부품의 고장 원인 및 신뢰성 분석\n",
      "직렬 시스템의 고장 원인은 대부분 내부 부품 고장에 의한 것이다. 부품별 고장 원인을 분석하기 위해 경쟁 위험모델을 적용한 경쟁 고장모드(CFM)를 사용한다. 기존 분석도구인 ReliaSoft에서의 CFM 계산은 기존의 수치해석법을 따른 것으로 판단이 된다. 본 논문에서는 이를 개선하기 위해서 EM 알고리즘을 이용한 경쟁 고장모드를 소개한다. 그리고 중단된 데이터가 포함된 고장모드를 지녔을 때와 3가지 고장모드를 지녔을 때의 실제 데이터를 통해 기존 분석도구 결과와 비교한다. 또한 신뢰도 측정치(신뢰도, 특성수명)를 ReliaSoft의 결과와 비교하였다. 제안하는 방법은 R 프로그램을 이용하여 쉽게 구현할 수 있다.\n",
      "\n",
      "Consider a system comprising multiple components connected in series. The failure of the whole system is caused by the earliest failure of any of the components; this is commonly referred to as the competing failure mode (CFM). It is also known as the competing risks model in the literature. Many analysis tools, such as ReliaSoft, include the CFM method; however, they do not provide a good fit compared with the EM algorithm method for CFMs. In this paper, we introduce CFMs using the EM algorithm. We applied real data examples with three failure modes to estimate the shape and scale parameters of the system. In addition, reliability measures (reliability and characteristic life) were compared with ReliaSoft results. The proposed method can be easily implemented using the developed R program.\n",
      "\n",
      "통계적 추정기 및 LPC 잔차잡음 억제에 기반한 음성강조 알고리즘의 SNR 효과\n",
      "음성에 잡음이 중첩된 경우에 음성에 대한 선형예측 정밀도가 감소하게 되어 재생된 음성의 품질이 떨어진다. 따라서 본 논문에서는 다양한 잡음이 포함된 음성신호에 대하여 통계적 추정기에 의해서 개선된 선형예측계수의 잔차신호를 사용하여 잡음제거를 목적으로 한 음성강조 알고리즘을 제안한다. 본 실험에서는 신호처리에 의한 SN비의 개선을 목적으로 하여 5종류의 배경잡음에 의하여 중첩된 음성신호를 사용하여 입력 SNR이 약 0㏈∼4㏈인 경우에 대하여 실험을 진행하였으며, 각 잡음이 중첩된 음성에 대하여 출력 SNR이 평균 4.99(㏈), 5.10(㏈), 5.14(㏈), 6.40(㏈), 6.59(㏈) 개선된 것을 알 수 있었다. 따라서 본 논문에서 제안한 알고리즘은 잡음억제의 SNR의 양호한 결과로부터 음성강조의 효과가 크다는 것을 명확히 할 수 있었다.\n",
      "\n",
      "When noise signal is included in speech, linear prediction accuracy for the speech is reduced, and thus the quality of the reproduced speech is degraded. Therefore, this paper proposes a speech enhancement algorithm for reducing the noise using the residual signal of the linear predictive coefficient improved by statistical estimator, for various noisy speech signals. In this experiment, for the purpose of improving the SNR by signal processing, this experiment was conducted for the case where the input SNRs are about 0㏈ to 4㏈ using noisy speech signal contaminated by 5 types of background noises. From these experiment results, it was confirmed that output SNRs improved by averages of 4.99(㏈), 5.10(㏈), 5.14(㏈), 6.40(㏈), and 6.59(㏈) for each noisy speech signal. Therefore, it was clarified that the proposed algorithm has a good effect of speech enhancement from the SNR noise reduction results.\n",
      "\n",
      "개인맞춤형 건강식생활 정보제공 알고리즘 개발을 위한 Q분석기법 활용 연구 : 대학생을 중심으로\n",
      "이 연구는 주제 관련 대학생들이 인식하는 개인맞춤형 건강식생활 정보제공 알고리즘 개발에 관한 주관성을 진단하고, 기능적인 측면에서 세부적인 유형적 효과요인들을 확인하여 향후 개선과 방향성을 알아보고자 하였다. 연구분석을 위해서 연구진에서는 Q방법론을 이용하였다. 분석된 결과, 총 5가지의 유형, 즉 유형Ⅰ[(n=7) : 식사 조절 정보 유형], 유형Ⅱ[(n=2) : 적정 음식 섭취 정보 유형], 유형Ⅲ[(n=3) : 선별적 음식 정보 유형], 유형Ⅳ[(n=2) : 인스턴트 제한 정보 유형], 유형Ⅴ[(n=1) : 건강증진식품 정보 유용성 유형] 등으로 분류되었다. 또한 QUANL 프로그램을 실시해 본 결과, 전체변량의 약 60(0.5993)%를 설명하였다. 결과적으로, 앞으로 계량적인 실증적 연구와 소비자들의 의견을 종합한 비교와 대안책이 추가된다면, 주제 관련 일반 소비자들의 주관성에 관한 보다 심도 있는 연구결과가 제시될 수 있을 것으로 예상된다. 또한, 이러한 연구의 한계를 보완하는 후속연구가 지속적으로 진행되어지기를 기대한다.\n",
      "\n",
      "This paper-work was carried out by practical method in a subjectivity study accessible in-depth, in getting out of past convention of technical quantity analysis on health-food-life information-providing in personal-target type through Q-analysis(QUANL program). The perception pattern come out in this study were divided into a five types, it is that is Ⅰ[(n=7) : meal control information type], Ⅱ[(n=2) : reasonable food intake-information type Ⅲ[(n=3) : selective food information type], Ⅳ[(n=2) : instant limited-information type], Ⅴ[(n=1) : health-promotion-food information usefulness type], and analysed in about 60(0.5993)% in cumulative result(explanation) side. There are a various ‘health-food-life’ images. In conclusion side, this study is to ascertain acceptance behavior about reception type on health-food-life information-providing in personal-target type through Q-analysis ; to propose a developmental suggestion about it.\n",
      "\n",
      "스마트시티 데이터허브를 활용한 공조시스템용 에너지소비량 절감 알고리즘 개발\n",
      "공기조화시스템은 건물 내 공기의 질을 이용자들의 활동에 쾌적하도록 유지해주는 기술 일체를 뜻한다. 대형 건축물의 중앙식 공조시스템은 미리 설계된 매뉴얼에 맞추어 단순하게 운영되기에, 건물에너지의 낭비를 초래하고, 실내 공기질 개선 등 이용자의 요구사항 반영에도 난점을 지닌다. 다양한 도시 데이터를 바탕으로 시민 삶의 질 향상을 목표로 하는 스마트시티와 데이터허브의 도입은 기존 공기조화시스템 개선의 동력이 될 수 있다. 본 논문은 페르소나 기법을 활용하여 테스트 건물인 서울대학교 시흥캠퍼스 교육협력동 이용자들의 니즈를 파악하고, 스마트시티 데이터허브의 데이터를 활용하는 공조시스템 실시간 운영 알고리즘을 제시한다. 알고리즘은 건물 내외 이산화탄소 농도, 미세먼지 농도, 온습도를 비교하여 공조시스템의 댐퍼 개도를 실시간으로 조절한다. 새로운 알고리즘은 공조시스템의 연간 에너지소비량을 기존 대비 32% 절감하고, 실내 미세먼지 및 이산화탄소 농도 또한 이용객의 쾌적 활동범위에서 유지한다.\n",
      "\n",
      "The HVAC system maintains the quality of air in the building to be comfortable for the inhabitants. As the HVAC system for large buildings has usually been operated manually, it has weaknesses in efficient use of energy and reflecting inhabitants’ needs such as air quality improvement. Development of smart city and data hubs, aimed at improving the quality of life of citizens based on various city data, can become a driving force in improving the conventional HVAC system. By using the persona technique, this paper identifies the needs of inhabitants of the test-bed building in Seoul National University and suggests algorithm that run the HVAC system in real-time using data collected through the smart city data hub. The algorithm is designed to adjust the damper position of the HVAC system real-time by comparing the levels of carbon dioxide, fine dust, and temperature and humidity inside and outside the building. Simulation results show that the new HVAC system saves 32% in annual energy consumption compared to the previous system and maintains the concentration of fine dust and carbon dioxide within the range of conditions that allow occupants to comfortably carry out activities.\n",
      "\n",
      "IQR알고리즘의 사분범위 조정을 활용한 당뇨 예측 방법\n",
      "본 논문에서는 당뇨병을 조기진단 및 예측하기 위해 머신러닝에 사용되는 당뇨데이터를 전처리하는 방법을 제안한다. 전처리 방법에는 의료데이터의 대표적인 문제인 결측치, 이상치, 클래스의 불균형문제를 포함하고 있다. 특히 이상치문제를 해결하기 위해 대표적으로 사용되는 IQR알고리즘은 데이터의 격차가 클 경우, 많은 양의 데이터를 이상치로 간주하기 때문에 본 논문에서는 기존의 IQR알고리즘이 아닌 알고리즘 내의 사분범위를 조정하여 입력데이터에 적합한 이상치제거 알고리즘을 제안하였다.결측치 및 클래스의 불균형 문제는 중앙값과 SMOTE알고리즘을 사용하여 문제를 해결하였다. 제안하는 전처리 방법을 사용하였을 경우, 기존의 이상치 알고리즘을 적용한 결과보다 5%의 우수한 성능을 나타내었으며, 또한 AUC수치 역시 4% 더 높은 성능을 보이고 있다.\n",
      "\n",
      "In this paper, a method of pretreatment of diabetes data used in machine learning is proposed to diagnose and predict diabetes early. The preprocessing methods include missing values, abnormal values, and level imbalance, which are representative problems in medical data. In particular, the IQR algorithm, which is used to solve the ideal value problem, considers a large amount of data as ideal value when the data gap is large, so this paper proposes an ideal value elimination algorithm suitable for input data. The median and SMOTE algorithms are used to solve the problem of missing values and grade imbalance. The proposed pretreatment method shows 5% better performance than the previous ideal value algorithm, and the AUC value is also 4%.\n",
      "\n",
      "남극 환경에서 다중 로봇 시스템을 위한 최근접 이웃 알고리즘 기반 효율적 다중 작업 스케줄링\n",
      "This paper addresses the problem of multi-robot task scheduling in Antarctic environments. It is difficult to operate multiple robots in Antarctic environments due to the icy ground condition and the lack of powers. In our previous work, the multi-robot task scheduling in Antarctic environments has been solved using ant colony optimization. Although it worked successfully, it caused much computation time. This paper proposes an efficient multi-robot task scheduling approach using nearest neighbor algorithm in Antarctic environments. The proposed method was tested in both simulated environments and Antarctic environments. The proposed method showed better performance in terms of computation time and cost than ant colony optimization and genetic algorithm.\n",
      "\n",
      "UAV 지원 Cellular-connected 시스템에서 Position Fingerprint Database를 이용한 협력적 빔 선택 알고리즘\n",
      "UAV (Unmanned Aerial Vehicle)는 높은 고도와 이동성의 특징 때문에, 지상 네트워크의 한계를 넘을 수 있어 NR (New Radio) 시스템의 핵심 요소로 주목받고 있다. 하지만 높은 고도의 UAV는 높은 LOS (Line-Of-Sight) 확률로 다른 셀 간 간섭의 영향을 크게 받을 수 있다. 이에 본 논문에서는 간섭의 영향을 줄이고, 전송 효율을 최대화할 수 있도록 최적의 빔을 선택하는 알고리즘을 제안한다. 제안 알고리즘은 크게 두 단계로 구성된다. 본 논문에서 제시한 사용자 타입에 맞게 필요한 정보를 저장하는 사용자 위치 기반 핑거프린트 데이터베이스 (Fingerprint Database)를 구축하는 과정과 협력적 빔 선택 과정으로 나뉜다. 성능 분석을 위해 셀룰러 협력 다운링크 시스템을 기반으로 모의실험을 진행하였고, 성능 분석 지표로는 신호 대 간섭 및 잡음 비율의 누적 분포 함수 (SINR CDF, Signal-to-Interference-plus-Noise Ratio Cumulative Distribution Function)와 스펙트럼 효율의 누적 분포 함수 (SE CDF, Spectral Efficiency Cumulative Distribution Function)를 사용하였다. 성능 분석 결과 제안 알고리즘이 간섭의 영향은 줄이고, 원하는 신호의 성능은 높인다는 점을 확인하였다. 또한, 정보 교환에 필요한 자원의 양을 줄임으로써 오버헤드 및 시스템의 비용을 고려한 효율적인 알고리즘이 될 수 있음을 확인하였다.\n",
      "\n",
      "Due to its high altitude and mobility characteristics, unmanned aerial vehicle (UAV) is attracting attention as a key element of new radio (NR) systems as they can exceed the limits of terrestrial networks. However, high line-of-sight (LOS) probability due to high altitude can be greatly affected by interference between different cells. Accordingly, this paper proposes an algorithm that select optimal beam to reduce the impact of interference, and maximize transmission efficiency. The proposed algorithm consists largely of two steps. According to the user type presented in this paper, it is divided into a process of constructing a user position-based fingerprint database and a process of cooperative beam selection process. Simulations were conducted based on cellular cooperative downlink systems for performance analysis, and signal-to-interference-plus-noise cumulative distribution function (SINR CDF) and spectral efficiency cumulative distribution function (SE CDF) were used as performance analysis indicators. As a result of performance analysis, it was confirmed that the proposed algorithm can reduce the effect of interference and increase the performance of the desired signal. Also, it was confirmed that it is an efficient algorithm that considers overhead and system costs by reducing the amount of resources required for information exchange.\n",
      "\n",
      "계산 광학 현미경: 알고리즘을 이용한 영상 복원 기술\n",
      "Like a mobile phone camera, optical microscopy typically relies on optical lenses that convert a plane wave to a spherical wave or vice versa. In such conventional imaging scheme, light from an object point propagates through a set of lenses and creates a tight focus on a camera, resulting in 1 to 1 relation between the object point and the camera pixel. Recently, this conventional imaging paradigm has been challenged by a new paradigm where computational algorithms replace the role of lenses. Here, I will introduce the concept of computational optics and some novel microscopy techniques based on algorithms.\n",
      "\n",
      "센서 데이터 기반의 타이어 상태진단 알고리즘 개발\n",
      "Purpose: Tire maintenance is essential for safety, as tire failure can cause significant damage to human health and infrastructure during light rail operations. Therefore, we developed a diagnostic algorithm for light rail rubber tires to prevent such catastrophic events.\n",
      "Methods: Vibration signals measured by tri-axis accelerometers were acquired during real-world light rail operation, and we compared vibrations among various tire states, established a health index, and developed a model for determining tire state.\n",
      "Results: The most important type of vibration in terms of tire state was x-axis vibration. Our model determined tire states by calculating x-axis vibration differences in various tire conditions. Furthermore, high model accuracy was confirmed by stratified k-fold cross-validation.\n",
      "Conclusion: Our diagnostic algorithm for determining tire condition reduces operating and support costs and promotes reliability and safety by enabling timely and appropriate maintenance that considers the age of individual tires. Thus, it could replace existing time-based maintenance protocols.\n",
      "\n",
      "Depth Camera와 GPS를 활용한 실시간 객체 좌표 생성 알고리즘 개발\n",
      "뎁스 카메라를 이용한 다양한 연구가 많이 발전하고 있다. 본 논문은 이러한 추세에 발맞춰 뎁스 카메라와 RGB 카메라를 동시에 이용하여 실시간 물체의 GPS UTM 좌표를 찾는 연구를 수행했다. 먼저 해상도가 다른 두 카메라의 해상도 매칭을 수행한 후, RGB 카메라와 인식된 물체의 경계 상자의 중앙 픽셀 좌표를 사용해 객체 인식을 한다. 그 후, 카메라로부터 객체까지의 거리를 같은 픽셀로 해상도를 맞춘 뎁스 카메라를 사용해 측정했다. 카메라 픽셀의 초점, 객체 경계 상자의 중심 픽셀 좌표, 뎁스 카메라로 구한 거리를 통해 카메라에서 객체까지의 X, Y 거리를 계산했다. 그런 다음 카메라와 같은 위치에 있는 GPS의 UTM 좌푯값, GPS의 이전 좌표를 통해 추출된 방향, 카메라가 얻은 객체로부터 떨어진 X, Y 거리 등을 계산해 계산된 값을 측정했다. 실험 결과의 정확성을 위해 GPS를 통해 특정 지점의 거리와 UTM 좌표를 미리 구한 뒤 실제 사람이 그 위치에 서서 객체를 인식뒤 정확도를 판단했다. 실험 결과, 10m 이내에서 높은 정확도의 결과를 얻었다.\n",
      "\n",
      "Various studies using depth cameras are developing a lot. In line with the trend, this paper conducted a study to find GPS UTM coordinates of real-time objects using a camera with a depth camera and an RGB camera at the same time. After first performing resolution matching of two cameras with different resolutions, we find out object recognition using RGB cameras and central pixel coordinates of the bounding box of the recognized object. After that, the distance from the camera to the object was measured using a depth camera that matched the resolution with the same pixel. X and Y distances away from the camera to the object were calculated through the focus of the camera pixel, the center pixel coordinates of the bounding box of the object, and the distance obtained by the depth camera. Then, the calculated value was calculated by the UTM coordinate value of GPS in the same position as the camera, the heading direction extracted through the previous coordinates of GPS, and the X and Y distances away from the object obtained by the camera. For the accuracy of the experimental results, the distance and UTM coordinates of a particular point were obtained in advance through GPS, and then a real person stood at the location and recognized the object, and then the accuracy was determined. As a result of the experiment, a result with high accuracy was obtained within 10m.\n",
      "\n",
      "고해상도 단순 이미지의 객체 분류 학습모델 구현을 위한 개선된 CNN 알고리즘 연구\n",
      "CNN(Convolutional Neural Network) 알고리즘은 인공신경망 구현에 활용되는 대표적인 알고리즘으로 기존 FNN(Fully connected multi layered Neural Network)의 문제점인 연산의 급격한 증가와 낮은 객체 인식률을 개선하였다. 그러나 IT 기기들의 급격한 발달로 최근 출시된 스마트폰 및 태블릿의 카메라에 촬영되는 이미지들의 최대 해상도는 108MP로 약 1억 8백만 화소이다. 특히 CNN 알고리즘은 고해상도의 단순 이미지를 학습 및 처리에 많은 비용과 시간이 요구된다. 이에 본 논문에서는 고해상도 단순 이미지의 객체 분류 학습모델 구현을 위한 개선된 CNN 알고리즘을 제안한다. 제안하는 알고리즘은 고해상도의 이미지들의 학습모델 생성 시간을 감소하기 위해 CNN 알고리즘의 풀링계층의 Max Pooling 알고리즘 연산을 위한 인접 행렬 값을 변경한다. 변경한 행렬 값마다 4MP, 8MP, 12MP의 고해상도 이미지들의 처리할 수 있는 학습 모델들을 구현한다. 성능평가 결과, 제안하는 알고리즘의 학습 모델의 생성 시간은 12MP 기준 약 36.26%의 감소하고, 학습 모델의 객체 분류 정확도와 손실률은 기존 모델 대비 약 1% 이내로 오차 범위 안에 포함되어 크게 문제가 되지 않는다. 향후 본 연구에서 사용된 학습 데이터보다 다양한 이미지 종류 및 실제 사진으로 학습 모델을 구현한 실질적인 검증이 필요하다.\n",
      "\n",
      "A convolutional neural network (CNN) is a representative algorithm for implementing artificial neural networks. CNNs have improved on the issues of rapid increase in calculation amount and low object classification rates, which are associated with a conventional multi-layered fully-connected neural network (FNN). However, because of the rapid development of IT devices, the maximum resolution of images captured by current smartphone and tablet cameras has reached 108 million pixels (MP). Specifically, a traditional CNN algorithm requires a significant cost and time to learn and process simple, high-resolution images. Therefore, this study proposes an improved CNN algorithm for implementing an object classification learning model for simple, high-resolution images. The proposed method alters the adjacency matrix value of the pooling layer\"s max pooling operation for the CNN algorithm to reduce the high-resolution image learning model\"s creation time. This study implemented a learning model capable of processing 4, 8, and 12 MP high-resolution images for each altered matrix value. The performance evaluation result showed that the creation time of the learning model implemented with the proposed algorithm decreased by 36.26% for 12 MP images. Compared to the conventional model, the proposed learning model\"s object recognition accuracy and loss rate were less than 1%, which is within the acceptable error range. Practical verification is necessary through future studies by implementing a learning model with more varied image types and a larger amount of image data than those used in this study.\n",
      "\n",
      "여론조사와 빅 데이터를 융합한 예측 알고리즘 개발과 선거적용에 관한 연구\n",
      "2016년 미국 대통령 선거에서 대부분의 미국 여론조사 기관들은 힐러리 클린턴이 오차범위 밖에서 당선될 것을 예측했으나 결과적으로 도널드 트럼프가 대통령으로 당선되었다. 최근 한국에서도 선거 여론조사 결과가 조사기관 사이에 차이가 커서 불신을 받고 있으며 이를 보완할 새로운 방법이 필요하다. 선거 여론조사가 불신을 받는 원인으로는 제한된 표본의 수, 다양한 데이터 수집방법, 특정한 연령구간에 응답이 부족할 때 사용하는 보정기법으로 추정된다. 이 연구에서는 여론조사 결과에 포털 서비스, 블로그, 트위터, 인스타그램 등에서 후보자를 언급한 버즈량을 시간을 변수로 가중치를 부가하여 결합하며 여기에 검색어와 댓글의 긍·부정 반응을 점수를 가감하는 후처리 기법으로 선거결과를 예측하는 알고리즘을 개발한다. 성능평가를 위해 개발된 알고리즘을 지난 한국 대통령 선거 4개월 동안에 적용한다. 선거운동 기간에는 바로 다음 주 여론조사를 예측하고 투표일에는 대통령 당선자와 득표율을 예측하고 오차를 기존의 여론조사들과 비교, 분석한다.\n",
      "\n",
      "A lot of polling organizations predicted Hillary Clinton would win in 2016 USA presidential election over margin of error, though as a result, Donald Trump won. In Republic of Korea supplementary method should be found as many people distrust the opinion polls due to large deviation errors across survey organizations. Limited number of samples, too diverse data acquisition methods and correction techniques for lack of data at a certain age are the likely causes. This research develops a algorithm combining two different data sets, not only opinion poll but also buzz data from Internet portal services, blogs, Twitter and Instagram. These two are combined with assigning weighted values based upon time parameter. To enhance prediction reliability, adjustment technique using positive-negative scoring through figuring out search words and comments in SNS was post-processed as well. To evaluate prediction accuracy it is evaluated during four month Korea presidential election campaign. The prediction results are compared to the next the week opinion poll during campaign. At vote day this predicted the president-elect, and prediction errors to actual votes are computed and analysed, finally.\n",
      "\n",
      "킥보드 불법 주차 문제 해결을 위한 도착지 중심 스테이션 증설 알고리즘\n",
      "본 연구는 공유 전동 킥보드 불법 주차 문제를 해결하고 서비스 품질을 개선하기 위하여 새로운 스테이션 선정 알고리즘을 제안하는 것을 목표로 한다. 최근 도시 교통 문제의 해결 방안으로 대중교통과 최종 목적지를 연결하는 퍼스트-라스트 마일 수단으로 공유 전동 킥보드가 주목받고 있다. 그에 따라 공유 전동 킥보드 시장도 급속도로 성장하면서 그로 인한 문제 또한 심화되고 있다. 이에 본 연구에서는 문제의 본질을 파악하기 위해 텍스트 데이터를 수집하여 ‘LDA 토픽 모델링’으로 공유 킥보드에 관한 이슈를 보행자와 이용자 관점에서 살펴보고 이를 바탕으로 스테이션 증설 알고리즘을 마련하려 한다. 기존에 이미 일부 주차장이 설치되어 있지만 기존의 주차장 위치는 실제 견인 다발 지역과 불일치한다. 따라서 본 연구에서는 ‘서울특별시 전동 킥보드 견인 현황’ 데이터와 여러요인을 반영하여 DBSCAN을 통한 1차 클러스터링 후, K-means를 적용하는 혼합형 클러스터링 기법으로 실제 견인 밀도가 높은 곳에 스테이션을 설치할 수 있는 알고리즘을 제안한다.\n",
      "\n",
      "In this paper, we propose a new station selection algorithm to solve the illegal parking problem of shared electric scooters and improve the service quality. Recently, as a solution to the urban transportation problem, shared electric scooters are attracting attention as the first and last mile means between public transportation and final destinations. As a result, the shared electric scooter market grew rapidly, problems caused by electric scooters are becoming serious. Therefore, in this study, text data are collected to understand the nature of the problem, and the problems related to shared scooters are viewed from the perspective of pedestrians and users in ‘LDA Topic Modeling’, and a station extension algorithm is based on this. Some parking lots have already been installed, but the existing parking lot location is different from the actual area of tow. Therefore, in this study, we propose an algorithm that can install stations at high actual tow density using mixed clustering technology using K-means after primary clustering by DBSCAN, reflecting the ‘current state of electric scooter tow in Seoul’.\n",
      "\n",
      "Levenshtein Distance를 활용한 문자열 유사도 기반의 BIM 속성정보 CFD 매칭 알고리즘\n",
      "For attribute data matching between BIM and CFD, this study proposed a BIM attribute information matching algorithm based on string similarity using levenshtein distance. Considering the versatility of BIM and CFD models, algorithms were developed for IFC and OpenFOAM, which are open-source technologies. The algorithm consists of three modules. First of all, BIM attribute data extraction algorithm was established to extract attribute information from BIM. In addition, in order to input CFD of accurate property information, a database of property information on building materials was established. To implement a matching algorithm based on string similarity, the levenshtein distance algorithm, which calculates the editing distance between two strings, was applied. A matching algorithm was designed to convert the edit distance to similarity and input the attribute data of the selected optimal material to the CFD model. The attribute data of the material with the highest degree of similarity was input into the CFD model. Validation of the developed algorithm was conducted to evaluate the accuracy. As a result of validation, the BIM attribute information extraction algorithm was evaluated with an accuracy of about 99.1%. The matching algorithm accurately matched all materials belonging to the IFC to the CFD model. Therefore, the accuracy of the algorithm proposed in this study was validated.\n",
      "\n",
      "CMA-ES/SPGD 이중 알고리즘을 통한 결맞음 빔 결합 시스템 위상제어 및 동작성능에 대한 전산모사 분석\n",
      "본 연구에서는 다채널 결맞음 빔결합 시스템을 위한 위상제어 방식으로 covariant matrix adaption evolution strategy (CMA-ES) 알고리즘 및 stochastic parallel gradient descent (SPGD) 알고리즘을 결합한 이중 위상제어 알고리즘을 제안하고 그 동작 특성을 전산모사를 통해 분석한다. 제안하는 CMA-ES/SPGD 이중 위상제어 알고리즘은 결합된 최종 출력광 세기가 미리 설정된 특정값에 도달하기 전까지는 그 위상제어 최적화를 CMA-ES 알고리즘을 통해 진행하고, 그 이후에는 SPGD 알고리즘으로 전환하여 진행하는 순차적 이중 구조를 취한다. 이를 이상적인 7채널과 19채널 광섬유 결합기 기반 결맞음 빔결함 시스템에 적용하였을 때, 위상제어 최적화 평균 수렴시간이 기존의 SPGD 알고리즘만 단독적용한 경우에 비해 약 10% 단축됨을 확인하였다. 뿐만 아니라, 동일한 결맞음 빔결함 시스템에서 실제 환경과 유사하게 각 채널광에 위상잡음을 부가적으로 인가한 경우, 본 연구에서 제안하는 이중 위상제어 알고리즘을 적용할 경우 주어진 조건에서 그 평균 수렴시간이 기존의 SPGD 알고리즘만 단독적용한 경우에 비해 7채널 시스템의 경우 약 17%, 19채널 시스템의 경우 약 16–27% 정도 단축됨을 확인하였다. 본 연구에서 제안한 CMA-ES/SPGD 이중 위상제어 알고리즘은 향후 실제 대기 환경과 같이 위상잡음 효과를 무시할 수 없는 조건에서 결맞음 빔결합을 구현시 매우 유용하게 활용될 수 있을 것으로 기대된다.\n",
      "\n",
      "In this study, we propose a hybrid phase-control algorithm for multi-channel coherent beam combining (CBC) system by combining the covariant matrix adaption evolution strategy (CMA-ES) and stochastic parallel gradient descent (SPGD) algorithms and analyze its operational performance. The proposed hybrid CMA-ES/SPGD algorithm is a sequential process which initially runs the CMA-ES algorithm until the combined final output intensity reaches a preset interim value, and then switches to running the SPGD algorithm to the end of the whole process. For ideal 7-channel and 19-channel all-fiber-based CBC systems, we have found that the mean convergence time can be reduced by about 10% in comparison with the case when the SPGD algorithm is implemented alone. Furthermore, we analyzed a more realistic situation in which some additional phase noise was introduced in the same CBC system. As a result, it is shown that the proposed algorithm reduces the mean convergence time by about 17% for a 7-channel CBC system and 16–27% for a 19-channel system compared to the existing SPGD alone algorithm. We expect that for implementing a CBC system in a real outdoor environment where phase noise cannot be ignored, the hybrid CMA-ES/SPGD algorithm proposed in this study will be exploited very usefully.\n",
      "\n",
      "세그멘테이션 기반 차선 인식 네트워크를 위한 적응형 키포인트 추출 알고리즘\n",
      "딥러닝 기반의 이미지 세그멘테이션은 차선 인식을 위해 널리 사용되는 접근 방식 중 하나로, 차선의 키포인트를 추출하기 위한 후처리 과정이 필요하다. 일반적으로 키포인트는 사용자가 지정한 임계값을 기준으로 추출한다. 하지만 최적의 임계값을 찾는 과정은 큰 노력을 요구하며, 데이터 세트(또는 이미지)마다 최적의 값이 다를 수 있다. 본 연구는 사용자의 직접 임계값 지정 대신, 대상의 이미지에 맞추어 적절한 임계값을 자동으로 설정하는 키포인트 추출 알고리즘을 제안한다. 본 논문의 키포인트 추출 알고리즘은 차선 영역과 배경의 명확한 구분을 위해 줄 단위 정규화를 사용한다. 그리고 커널 밀도 추정을 사용하여, 각 줄에서 각 차선의 키포인트를 추출한다. 제안하는 알고리즘은 TuSimple과 CULane 데이터 세트에 적용되었으며, 고정된 임계값 사용 대비 정확도 및 거리오차 측면에서 1.80%p와 17.27% 향상된 결과를 얻는 것을 확인하였다.\n",
      "\n",
      "Deep-learning-based image segmentation is one of the most widely employed lane detection approaches, and it requires a post-process for extracting the key points on the lanes. A general approach for key-point extraction is using a fixed threshold defined by a user. However, finding the best threshold is a manual process requiring much effort, and the best one can differ depending on the target data set (or an image). We propose a novel key-point extraction algorithm that automatically adapts to the target image without any manual threshold setting. In our adaptive key-point extraction algorithm, we propose a line-level normalization method to distinguish the lane region from the background clearly. Then, we extract a representative key point for each lane at a line (row of an image) using a kernel density estimation. To check the benefits of our approach, we applied our method to two lane-detection data sets, including TuSimple and CULane. As a result, our method achieved up to 1.80%p and 17.27% better results than using a fixed threshold in the perspectives of accuracy and distance error between the ground truth key-point and the predicted point.\n",
      "\n",
      "AI 기반 수요예측 알고리즘 모바일 모니터링 애플리케이션 설계\n",
      "최근 많은 기업이 다양한 AI 기반 수요예측 알고리즘을 통해서 이익을 창출하기 위해 시스템을 구축하고 있다. 그렇기에 본 연구에서는 AI 수요예측 관련 자료를 사용자가 실시간으로 모니터링 할 수 있는 애플리케이션을 개발하고자 한다. 이 애플리케이션을 만들 때 정보를 쉽게 이해하도록 색채를 용도에 맞춤으로써 도움을 줄 수 있고, 레이아웃을 고려하여 정보를 쉽게 전달하고 한눈에 알아볼 수 있도록 하는 것이 목표이다. 또한, 아이디와 비밀번호 확인, 고유 코드 부분 구성에서 체크 박스 기능과 각 텍스트 기능을 이용하여 설계하였다. 기업별로 정해진 고유 코드를 이용하여 해당되는 기업의 데이터만 확인할 수 있게끔 하여 기밀 데이터 보안성을 강화할 수 있다. 그로 인해 실시간 모니터링을 모바일 애플리케이션으로 보안 문제없이 볼 수 있다.\n",
      "\n",
      "Recently, many companies are building systems to generate profits through various AI-based demand forecasting algorithms. Therefore, this study aims to develop an application that allows users to monitor data related to AI demand prediction in real time. When creating this application, the goal is to help you easily understand the information by adapting the color to the purpose, and to easily convey the information and recognize it at a glance by considering the layout. In addition, the design was constructed using the check box function and each text function in the ID and password verification and the unique code partial configuration. Confidential data security can be enhanced by allowing only the data of the corresponding company to be checked using the unique code set for each company. As a result, real-time monitoring can be viewed without security problems with mobile applications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(detail_url_list)):\n",
    "    print(title[i])\n",
    "    print(content[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = page_list.find_elements(By.TAG_NAME,'a')\n",
    "for p in range(2,4):\n",
    "    page[p].send_keys(Keys.ENTER)\n",
    "    time.sleep(2)\n",
    "\n",
    "\n",
    "# for i in range(2,4):\n",
    "#     page_url = \n",
    "#     time.sleep(1)\n",
    "# for p in page:\n",
    "#     print(p.get_attribute('onclick'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000100e39670 chromedriver + 4298352\n1   chromedriver                        0x0000000100e31bbc chromedriver + 4266940\n2   chromedriver                        0x0000000100a64758 chromedriver + 280408\n3   chromedriver                        0x0000000100a680c8 chromedriver + 295112\n4   chromedriver                        0x0000000100a67d74 chromedriver + 294260\n5   chromedriver                        0x0000000100a68170 chromedriver + 295280\n6   chromedriver                        0x0000000100aa09e0 chromedriver + 526816\n7   chromedriver                        0x0000000100aa0b90 chromedriver + 527248\n8   chromedriver                        0x0000000100a96e20 chromedriver + 486944\n9   chromedriver                        0x0000000100a93b90 chromedriver + 474000\n10  chromedriver                        0x0000000100ad8080 chromedriver + 753792\n11  chromedriver                        0x0000000100a922d0 chromedriver + 467664\n12  chromedriver                        0x0000000100a93354 chromedriver + 471892\n13  chromedriver                        0x0000000100df96c4 chromedriver + 4036292\n14  chromedriver                        0x0000000100dfdc64 chromedriver + 4054116\n15  chromedriver                        0x0000000100e042d8 chromedriver + 4080344\n16  chromedriver                        0x0000000100dfe970 chromedriver + 4057456\n17  chromedriver                        0x0000000100dd58dc chromedriver + 3889372\n18  chromedriver                        0x0000000100e1d25c chromedriver + 4182620\n19  chromedriver                        0x0000000100e1d3b4 chromedriver + 4182964\n20  chromedriver                        0x0000000100e2c0f4 chromedriver + 4243700\n21  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n22  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m page[\u001b[39m7\u001b[39;49m]\u001b[39m.\u001b[39;49msend_keys(Keys\u001b[39m.\u001b[39;49mENTER)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[0;34m(self, *value)\u001b[0m\n\u001b[1;32m    228\u001b[0m             remote_files\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upload(file))\n\u001b[1;32m    229\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(remote_files)\n\u001b[0;32m--> 231\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(\n\u001b[1;32m    232\u001b[0m     Command\u001b[39m.\u001b[39;49mSEND_KEYS_TO_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(keys_to_typing(value)), \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: keys_to_typing(value)}\n\u001b[1;32m    233\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:404\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    402\u001b[0m     params \u001b[39m=\u001b[39m {}\n\u001b[1;32m    403\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[0;32m--> 404\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[1;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000100e39670 chromedriver + 4298352\n1   chromedriver                        0x0000000100e31bbc chromedriver + 4266940\n2   chromedriver                        0x0000000100a64758 chromedriver + 280408\n3   chromedriver                        0x0000000100a680c8 chromedriver + 295112\n4   chromedriver                        0x0000000100a67d74 chromedriver + 294260\n5   chromedriver                        0x0000000100a68170 chromedriver + 295280\n6   chromedriver                        0x0000000100aa09e0 chromedriver + 526816\n7   chromedriver                        0x0000000100aa0b90 chromedriver + 527248\n8   chromedriver                        0x0000000100a96e20 chromedriver + 486944\n9   chromedriver                        0x0000000100a93b90 chromedriver + 474000\n10  chromedriver                        0x0000000100ad8080 chromedriver + 753792\n11  chromedriver                        0x0000000100a922d0 chromedriver + 467664\n12  chromedriver                        0x0000000100a93354 chromedriver + 471892\n13  chromedriver                        0x0000000100df96c4 chromedriver + 4036292\n14  chromedriver                        0x0000000100dfdc64 chromedriver + 4054116\n15  chromedriver                        0x0000000100e042d8 chromedriver + 4080344\n16  chromedriver                        0x0000000100dfe970 chromedriver + 4057456\n17  chromedriver                        0x0000000100dd58dc chromedriver + 3889372\n18  chromedriver                        0x0000000100e1d25c chromedriver + 4182620\n19  chromedriver                        0x0000000100e1d3b4 chromedriver + 4182964\n20  chromedriver                        0x0000000100e2c0f4 chromedriver + 4243700\n21  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n22  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "page[7].send_keys(Keys.ENTER)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"4ebb58c2e0062ce3de598e910a0ddc4e\", element=\"f366d379-6113-4413-bb04-34b4aa0cff28\")>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98#a'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page[5].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000100e39670 chromedriver + 4298352\n1   chromedriver                        0x0000000100e31bbc chromedriver + 4266940\n2   chromedriver                        0x0000000100a64758 chromedriver + 280408\n3   chromedriver                        0x0000000100a680c8 chromedriver + 295112\n4   chromedriver                        0x0000000100a67d74 chromedriver + 294260\n5   chromedriver                        0x0000000100a68170 chromedriver + 295280\n6   chromedriver                        0x0000000100aa09e0 chromedriver + 526816\n7   chromedriver                        0x0000000100aa0b90 chromedriver + 527248\n8   chromedriver                        0x0000000100a96e20 chromedriver + 486944\n9   chromedriver                        0x0000000100a93b90 chromedriver + 474000\n10  chromedriver                        0x0000000100ad8080 chromedriver + 753792\n11  chromedriver                        0x0000000100a922d0 chromedriver + 467664\n12  chromedriver                        0x0000000100a93354 chromedriver + 471892\n13  chromedriver                        0x0000000100df96c4 chromedriver + 4036292\n14  chromedriver                        0x0000000100dfdc64 chromedriver + 4054116\n15  chromedriver                        0x0000000100e042d8 chromedriver + 4080344\n16  chromedriver                        0x0000000100dfe970 chromedriver + 4057456\n17  chromedriver                        0x0000000100dd58dc chromedriver + 3889372\n18  chromedriver                        0x0000000100e1d25c chromedriver + 4182620\n19  chromedriver                        0x0000000100e1d3b4 chromedriver + 4182964\n20  chromedriver                        0x0000000100e2c0f4 chromedriver + 4243700\n21  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n22  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     page[p]\u001b[39m.\u001b[39;49msend_keys(Keys\u001b[39m.\u001b[39;49mENTER)\n\u001b[1;32m      3\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[0;34m(self, *value)\u001b[0m\n\u001b[1;32m    228\u001b[0m             remote_files\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upload(file))\n\u001b[1;32m    229\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(remote_files)\n\u001b[0;32m--> 231\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(\n\u001b[1;32m    232\u001b[0m     Command\u001b[39m.\u001b[39;49mSEND_KEYS_TO_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(keys_to_typing(value)), \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: keys_to_typing(value)}\n\u001b[1;32m    233\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:404\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    402\u001b[0m     params \u001b[39m=\u001b[39m {}\n\u001b[1;32m    403\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[0;32m--> 404\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[1;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000100e39670 chromedriver + 4298352\n1   chromedriver                        0x0000000100e31bbc chromedriver + 4266940\n2   chromedriver                        0x0000000100a64758 chromedriver + 280408\n3   chromedriver                        0x0000000100a680c8 chromedriver + 295112\n4   chromedriver                        0x0000000100a67d74 chromedriver + 294260\n5   chromedriver                        0x0000000100a68170 chromedriver + 295280\n6   chromedriver                        0x0000000100aa09e0 chromedriver + 526816\n7   chromedriver                        0x0000000100aa0b90 chromedriver + 527248\n8   chromedriver                        0x0000000100a96e20 chromedriver + 486944\n9   chromedriver                        0x0000000100a93b90 chromedriver + 474000\n10  chromedriver                        0x0000000100ad8080 chromedriver + 753792\n11  chromedriver                        0x0000000100a922d0 chromedriver + 467664\n12  chromedriver                        0x0000000100a93354 chromedriver + 471892\n13  chromedriver                        0x0000000100df96c4 chromedriver + 4036292\n14  chromedriver                        0x0000000100dfdc64 chromedriver + 4054116\n15  chromedriver                        0x0000000100e042d8 chromedriver + 4080344\n16  chromedriver                        0x0000000100dfe970 chromedriver + 4057456\n17  chromedriver                        0x0000000100dd58dc chromedriver + 3889372\n18  chromedriver                        0x0000000100e1d25c chromedriver + 4182620\n19  chromedriver                        0x0000000100e1d3b4 chromedriver + 4182964\n20  chromedriver                        0x0000000100e2c0f4 chromedriver + 4243700\n21  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n22  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "for p in range(1,3):\n",
    "    page[p].send_keys(Keys.ENTER)\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000100e39670 chromedriver + 4298352\n1   chromedriver                        0x0000000100e31bbc chromedriver + 4266940\n2   chromedriver                        0x0000000100a64758 chromedriver + 280408\n3   chromedriver                        0x0000000100a680c8 chromedriver + 295112\n4   chromedriver                        0x0000000100a67d74 chromedriver + 294260\n5   chromedriver                        0x0000000100a68170 chromedriver + 295280\n6   chromedriver                        0x0000000100aa09e0 chromedriver + 526816\n7   chromedriver                        0x0000000100aa0b90 chromedriver + 527248\n8   chromedriver                        0x0000000100a96e20 chromedriver + 486944\n9   chromedriver                        0x0000000100a93b90 chromedriver + 474000\n10  chromedriver                        0x0000000100ad8080 chromedriver + 753792\n11  chromedriver                        0x0000000100a922d0 chromedriver + 467664\n12  chromedriver                        0x0000000100a93354 chromedriver + 471892\n13  chromedriver                        0x0000000100df96c4 chromedriver + 4036292\n14  chromedriver                        0x0000000100dfdc64 chromedriver + 4054116\n15  chromedriver                        0x0000000100e042d8 chromedriver + 4080344\n16  chromedriver                        0x0000000100dfe970 chromedriver + 4057456\n17  chromedriver                        0x0000000100dd58dc chromedriver + 3889372\n18  chromedriver                        0x0000000100e1d25c chromedriver + 4182620\n19  chromedriver                        0x0000000100e1d3b4 chromedriver + 4182964\n20  chromedriver                        0x0000000100e2c0f4 chromedriver + 4243700\n21  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n22  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m page[\u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39;49msend_keys(Keys\u001b[39m.\u001b[39;49mENTER)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[0;34m(self, *value)\u001b[0m\n\u001b[1;32m    228\u001b[0m             remote_files\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upload(file))\n\u001b[1;32m    229\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(remote_files)\n\u001b[0;32m--> 231\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(\n\u001b[1;32m    232\u001b[0m     Command\u001b[39m.\u001b[39;49mSEND_KEYS_TO_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(keys_to_typing(value)), \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: keys_to_typing(value)}\n\u001b[1;32m    233\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:404\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    402\u001b[0m     params \u001b[39m=\u001b[39m {}\n\u001b[1;32m    403\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[0;32m--> 404\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[1;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000100e39670 chromedriver + 4298352\n1   chromedriver                        0x0000000100e31bbc chromedriver + 4266940\n2   chromedriver                        0x0000000100a64758 chromedriver + 280408\n3   chromedriver                        0x0000000100a680c8 chromedriver + 295112\n4   chromedriver                        0x0000000100a67d74 chromedriver + 294260\n5   chromedriver                        0x0000000100a68170 chromedriver + 295280\n6   chromedriver                        0x0000000100aa09e0 chromedriver + 526816\n7   chromedriver                        0x0000000100aa0b90 chromedriver + 527248\n8   chromedriver                        0x0000000100a96e20 chromedriver + 486944\n9   chromedriver                        0x0000000100a93b90 chromedriver + 474000\n10  chromedriver                        0x0000000100ad8080 chromedriver + 753792\n11  chromedriver                        0x0000000100a922d0 chromedriver + 467664\n12  chromedriver                        0x0000000100a93354 chromedriver + 471892\n13  chromedriver                        0x0000000100df96c4 chromedriver + 4036292\n14  chromedriver                        0x0000000100dfdc64 chromedriver + 4054116\n15  chromedriver                        0x0000000100e042d8 chromedriver + 4080344\n16  chromedriver                        0x0000000100dfe970 chromedriver + 4057456\n17  chromedriver                        0x0000000100dd58dc chromedriver + 3889372\n18  chromedriver                        0x0000000100e1d25c chromedriver + 4182620\n19  chromedriver                        0x0000000100e1d3b4 chromedriver + 4182964\n20  chromedriver                        0x0000000100e2c0f4 chromedriver + 4243700\n21  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n22  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "page[2].send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_list = browser.find_element(By.ID,\"pageList\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98'\n",
    "browser.get(url)\n",
    "page_list = browser.find_element(By.ID,\"pageList\")\n",
    "page = page_list.find_elements(By.TAG_NAME,'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000100f55670 chromedriver + 4298352\n1   chromedriver                        0x0000000100f4dbbc chromedriver + 4266940\n2   chromedriver                        0x0000000100b80758 chromedriver + 280408\n3   chromedriver                        0x0000000100b840c8 chromedriver + 295112\n4   chromedriver                        0x0000000100b83d74 chromedriver + 294260\n5   chromedriver                        0x0000000100b84170 chromedriver + 295280\n6   chromedriver                        0x0000000100bbb81c chromedriver + 522268\n7   chromedriver                        0x0000000100bafb90 chromedriver + 474000\n8   chromedriver                        0x0000000100bf4080 chromedriver + 753792\n9   chromedriver                        0x0000000100bae2d0 chromedriver + 467664\n10  chromedriver                        0x0000000100baf354 chromedriver + 471892\n11  chromedriver                        0x0000000100f156c4 chromedriver + 4036292\n12  chromedriver                        0x0000000100f19c64 chromedriver + 4054116\n13  chromedriver                        0x0000000100f202d8 chromedriver + 4080344\n14  chromedriver                        0x0000000100f1a970 chromedriver + 4057456\n15  chromedriver                        0x0000000100ef18dc chromedriver + 3889372\n16  chromedriver                        0x0000000100f3925c chromedriver + 4182620\n17  chromedriver                        0x0000000100f393b4 chromedriver + 4182964\n18  chromedriver                        0x0000000100f480f4 chromedriver + 4243700\n19  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n20  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhttps://www.dbpia.co.kr/search/topSearch?searchOption=all&query=\u001b[39m\u001b[39m%E\u001b[39;00m\u001b[39mC\u001b[39m\u001b[39m%95%\u001b[39;00m\u001b[39m8C\u001b[39m\u001b[39m%E\u001b[39;00m\u001b[39mA\u001b[39m\u001b[39m%\u001b[39m\u001b[39mB3\u001b[39m\u001b[39m%\u001b[39m\u001b[39mA0\u001b[39m\u001b[39m%E\u001b[39;00m\u001b[39mB\u001b[39m\u001b[39m%\u001b[39m\u001b[39mA6\u001b[39m\u001b[39m%\u001b[39m\u001b[39mAC\u001b[39m\u001b[39m%E\u001b[39;00m\u001b[39mC\u001b[39m\u001b[39m%\u001b[39m\u001b[39mA6\u001b[39m\u001b[39m%\u001b[39m\u001b[39m98\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     20\u001b[0m browser\u001b[39m.\u001b[39mget(url)\n\u001b[0;32m---> 23\u001b[0m page \u001b[39m=\u001b[39m page_list\u001b[39m.\u001b[39;49mfind_elements(By\u001b[39m.\u001b[39;49mTAG_NAME,\u001b[39m'\u001b[39;49m\u001b[39ma\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m page[p]\u001b[39m.\u001b[39msend_keys(Keys\u001b[39m.\u001b[39mENTER)\n\u001b[1;32m     25\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:448\u001b[0m, in \u001b[0;36mWebElement.find_elements\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    445\u001b[0m     by \u001b[39m=\u001b[39m By\u001b[39m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m    446\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 448\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(Command\u001b[39m.\u001b[39;49mFIND_CHILD_ELEMENTS, {\u001b[39m\"\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m\"\u001b[39;49m: by, \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: value})[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:404\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    402\u001b[0m     params \u001b[39m=\u001b[39m {}\n\u001b[1;32m    403\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[0;32m--> 404\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[1;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000100f55670 chromedriver + 4298352\n1   chromedriver                        0x0000000100f4dbbc chromedriver + 4266940\n2   chromedriver                        0x0000000100b80758 chromedriver + 280408\n3   chromedriver                        0x0000000100b840c8 chromedriver + 295112\n4   chromedriver                        0x0000000100b83d74 chromedriver + 294260\n5   chromedriver                        0x0000000100b84170 chromedriver + 295280\n6   chromedriver                        0x0000000100bbb81c chromedriver + 522268\n7   chromedriver                        0x0000000100bafb90 chromedriver + 474000\n8   chromedriver                        0x0000000100bf4080 chromedriver + 753792\n9   chromedriver                        0x0000000100bae2d0 chromedriver + 467664\n10  chromedriver                        0x0000000100baf354 chromedriver + 471892\n11  chromedriver                        0x0000000100f156c4 chromedriver + 4036292\n12  chromedriver                        0x0000000100f19c64 chromedriver + 4054116\n13  chromedriver                        0x0000000100f202d8 chromedriver + 4080344\n14  chromedriver                        0x0000000100f1a970 chromedriver + 4057456\n15  chromedriver                        0x0000000100ef18dc chromedriver + 3889372\n16  chromedriver                        0x0000000100f3925c chromedriver + 4182620\n17  chromedriver                        0x0000000100f393b4 chromedriver + 4182964\n18  chromedriver                        0x0000000100f480f4 chromedriver + 4243700\n19  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n20  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "title = []\n",
    "content = []\n",
    "writer = []\n",
    "for p in range(2,5):\n",
    "    datas = browser.find_elements(By.CLASS_NAME,'thesis__link')\n",
    "    detail_url_list = []\n",
    "    for i in datas:\n",
    "        detail_url = i.get_attribute('href')\n",
    "        detail_url_list.append(detail_url)\n",
    "    for i in detail_url_list:\n",
    "        browser.get(i)\n",
    "        title.append(browser.find_element(By.ID,'thesisTitle').text)\n",
    "        try:\n",
    "            content.append(browser.find_element(By.CLASS_NAME,'abstractTxt').text)\n",
    "        except:\n",
    "            content.append(\"no element.\")\n",
    "            continue\n",
    "    \n",
    "    url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98'\n",
    "    browser.get(url)\n",
    "\n",
    "    \n",
    "    page = page_list.find_elements(By.TAG_NAME,'a')\n",
    "    page[p].send_keys(Keys.ENTER)\n",
    "    time.sleep(1)\n",
    "for i in range(len(detail_url_list)):\n",
    "    print(title[i])\n",
    "    print(content[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in detail_url_list:\n",
    "    browser.get(i)\n",
    "    title.append(browser.find_element(By.ID,'thesisTitle').text)\n",
    "    try:\n",
    "        content.append(browser.find_element(By.CLASS_NAME,'abstractTxt').text)\n",
    "    except:\n",
    "        content.append(\"no element.\")\n",
    "        continue\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(detail_url_list)):\n",
    "    print(title[i])\n",
    "    print(content[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "플랫폼노동의 알고리즘 현황과 대응방안 – 알고리즘의 공정성과 투명성, 노동자 통제를 중심으로\n",
      "no element.\n",
      "\n",
      "선박 추진용 2행정 저속엔진의 고장모드 데이터 개발 및 LSTM 알고리즘을 활용한 특성인자 신뢰성 검증연구\n",
      "In the 4th industrial revolution, changes in the technological paradigm have had a direct impact on the maintenance system of ships. The 2-stroke low speed engine system integrates with the core equipment required for propulsive power. The Condition Based Management (CBM) is defined as a technology that predictive maintenance methods in existing calender-based or running time based maintenance systems by monitoring the condition of machinery and diagnosis/prognosis failures. In this study, we have established a framework for CBM technology development on our own, and are engaged in engineering-based failure analysis, data development and management, data feature analysis and pre-processing, and verified the reliability of failure mode DB using LSTM algorithms. We developed various simulated failure mode scenarios for 2-stroke low speed engine and researched to produce data on onshore basis test_beds. The analysis and pre-processing of normal and abnormal status data acquired through failure mode simulation experiment used various Exploratory Data Analysis (EDA) techniques to feature extract not only data on the performance and efficiency of 2-stroke low speed engine but also key feature data using multivariate statistical analysis. In addition, by developing an LSTM classification algorithm, we tried to verify the reliability of various failure mode data with time-series characteristics.\n",
      "\n",
      "방향을 가진 물체 인식 알고리즘과 조립 전략을 활용한 단일 하네스 케이블 조립 공정\n",
      "In this paper, we introduce a novel harness cable assembly process for a single wire. The assembly process consists of two main procedures. First, with a single RGB camera, an oriented object detection algorithm was utilized to detect the orientation as well as the position of the cable. Through a series of calibration processes, the pose of the cable in camera coordinates was converted to that in robot coordinates and transmitted to a manipulator. Then, a 6-DOF manipulator performed a precise peg-in-hole task for the cable assembly through three assembly strategies; angle correction, lean-and-slide, and weaving. The feasibility of the proposed assembly process was validated with a success rate of 92 % by implementing several single-wire assembly tasks.\n",
      "\n",
      "시분할 다중 접속 기반 무선 메쉬 네트워크에서 브로드캐스트 스케줄링 문제를 위한 타부서치 알고리즘\n",
      "시분할 다중 접속 기반에서 브로드캐스트 스케줄링 문제는 타임 슬롯을 사용하여 모든 단말이 충돌 없이 전송할 수 있도록 설계하는 문제이다. 본 논문에서는 시분할 다중 접속 기반의 무선 메쉬 네트워크에서 브로드캐스트를 사용하는 노드의 전송 스케줄을 최적화하여 전체 전송 횟수와 타임 슬롯 이용률을 최대화하는 브로드캐스트 스케줄링 최적화 알고리즘을 제안한다. 제안된 최적화 알고리즘은 메타휴리스틱 방식 중 하나인 타부서치 알고리즘을 사용한다. 제안된 타부서치 알고리즘은 전체 전송 횟수를 최대화하는 목적함수를 사용하여 효율적인 이웃해 생성방식을 설계하였다. 본 논문에서는 네트워크에서 발생하는 모든 브로드캐스팅에 대하여 전체 전송 횟수와 타임 슬롯 이용률 관점에서 제안된 타부서치 알고리즘의 성능평가를 수행하였다. 성능평가 결과에서 제안된 타부서치 알고리즘은 이전에 제안된 다른 최적화 알고리즘보다 더 우수한 결과를 나타내었다.\n",
      "\n",
      "The broadcast scheduling problem based in the time division multiple access is a problem of designing that all nodes can transmit without collision using time slots. In this paper, we propose a broadcast scheduling optimization algorithm that maximizes the total number of transmissions and channel utilization by optimizing the transmission schedule of a node using broadcast in TDMA-based wireless mesh networks. The proposed optimization algorithm uses Tabu search as one of metaheuristic methods. The proposed Tabu search algorithm was used as an objective function to maximize the total number of transmissions, and the neighborhood generation method was efficiently designed. In this paper, performance evaluation of the proposed tabu search algorithm was performed in terms of the total number of transmissions and time slot utilization for all broadcasting occurring in the network. In the performance evaluation results, the proposed tabu search algorithm showed better results than other previously proposed optimization algorithms.\n",
      "\n",
      "EM 알고리즘을 이용한 기계부품의 고장 원인 및 신뢰성 분석\n",
      "직렬 시스템의 고장 원인은 대부분 내부 부품 고장에 의한 것이다. 부품별 고장 원인을 분석하기 위해 경쟁 위험모델을 적용한 경쟁 고장모드(CFM)를 사용한다. 기존 분석도구인 ReliaSoft에서의 CFM 계산은 기존의 수치해석법을 따른 것으로 판단이 된다. 본 논문에서는 이를 개선하기 위해서 EM 알고리즘을 이용한 경쟁 고장모드를 소개한다. 그리고 중단된 데이터가 포함된 고장모드를 지녔을 때와 3가지 고장모드를 지녔을 때의 실제 데이터를 통해 기존 분석도구 결과와 비교한다. 또한 신뢰도 측정치(신뢰도, 특성수명)를 ReliaSoft의 결과와 비교하였다. 제안하는 방법은 R 프로그램을 이용하여 쉽게 구현할 수 있다.\n",
      "\n",
      "Consider a system comprising multiple components connected in series. The failure of the whole system is caused by the earliest failure of any of the components; this is commonly referred to as the competing failure mode (CFM). It is also known as the competing risks model in the literature. Many analysis tools, such as ReliaSoft, include the CFM method; however, they do not provide a good fit compared with the EM algorithm method for CFMs. In this paper, we introduce CFMs using the EM algorithm. We applied real data examples with three failure modes to estimate the shape and scale parameters of the system. In addition, reliability measures (reliability and characteristic life) were compared with ReliaSoft results. The proposed method can be easily implemented using the developed R program.\n",
      "\n",
      "통계적 추정기 및 LPC 잔차잡음 억제에 기반한 음성강조 알고리즘의 SNR 효과\n",
      "음성에 잡음이 중첩된 경우에 음성에 대한 선형예측 정밀도가 감소하게 되어 재생된 음성의 품질이 떨어진다. 따라서 본 논문에서는 다양한 잡음이 포함된 음성신호에 대하여 통계적 추정기에 의해서 개선된 선형예측계수의 잔차신호를 사용하여 잡음제거를 목적으로 한 음성강조 알고리즘을 제안한다. 본 실험에서는 신호처리에 의한 SN비의 개선을 목적으로 하여 5종류의 배경잡음에 의하여 중첩된 음성신호를 사용하여 입력 SNR이 약 0㏈∼4㏈인 경우에 대하여 실험을 진행하였으며, 각 잡음이 중첩된 음성에 대하여 출력 SNR이 평균 4.99(㏈), 5.10(㏈), 5.14(㏈), 6.40(㏈), 6.59(㏈) 개선된 것을 알 수 있었다. 따라서 본 논문에서 제안한 알고리즘은 잡음억제의 SNR의 양호한 결과로부터 음성강조의 효과가 크다는 것을 명확히 할 수 있었다.\n",
      "\n",
      "When noise signal is included in speech, linear prediction accuracy for the speech is reduced, and thus the quality of the reproduced speech is degraded. Therefore, this paper proposes a speech enhancement algorithm for reducing the noise using the residual signal of the linear predictive coefficient improved by statistical estimator, for various noisy speech signals. In this experiment, for the purpose of improving the SNR by signal processing, this experiment was conducted for the case where the input SNRs are about 0㏈ to 4㏈ using noisy speech signal contaminated by 5 types of background noises. From these experiment results, it was confirmed that output SNRs improved by averages of 4.99(㏈), 5.10(㏈), 5.14(㏈), 6.40(㏈), and 6.59(㏈) for each noisy speech signal. Therefore, it was clarified that the proposed algorithm has a good effect of speech enhancement from the SNR noise reduction results.\n",
      "\n",
      "개인맞춤형 건강식생활 정보제공 알고리즘 개발을 위한 Q분석기법 활용 연구 : 대학생을 중심으로\n",
      "이 연구는 주제 관련 대학생들이 인식하는 개인맞춤형 건강식생활 정보제공 알고리즘 개발에 관한 주관성을 진단하고, 기능적인 측면에서 세부적인 유형적 효과요인들을 확인하여 향후 개선과 방향성을 알아보고자 하였다. 연구분석을 위해서 연구진에서는 Q방법론을 이용하였다. 분석된 결과, 총 5가지의 유형, 즉 유형Ⅰ[(n=7) : 식사 조절 정보 유형], 유형Ⅱ[(n=2) : 적정 음식 섭취 정보 유형], 유형Ⅲ[(n=3) : 선별적 음식 정보 유형], 유형Ⅳ[(n=2) : 인스턴트 제한 정보 유형], 유형Ⅴ[(n=1) : 건강증진식품 정보 유용성 유형] 등으로 분류되었다. 또한 QUANL 프로그램을 실시해 본 결과, 전체변량의 약 60(0.5993)%를 설명하였다. 결과적으로, 앞으로 계량적인 실증적 연구와 소비자들의 의견을 종합한 비교와 대안책이 추가된다면, 주제 관련 일반 소비자들의 주관성에 관한 보다 심도 있는 연구결과가 제시될 수 있을 것으로 예상된다. 또한, 이러한 연구의 한계를 보완하는 후속연구가 지속적으로 진행되어지기를 기대한다.\n",
      "\n",
      "This paper-work was carried out by practical method in a subjectivity study accessible in-depth, in getting out of past convention of technical quantity analysis on health-food-life information-providing in personal-target type through Q-analysis(QUANL program). The perception pattern come out in this study were divided into a five types, it is that is Ⅰ[(n=7) : meal control information type], Ⅱ[(n=2) : reasonable food intake-information type Ⅲ[(n=3) : selective food information type], Ⅳ[(n=2) : instant limited-information type], Ⅴ[(n=1) : health-promotion-food information usefulness type], and analysed in about 60(0.5993)% in cumulative result(explanation) side. There are a various ‘health-food-life’ images. In conclusion side, this study is to ascertain acceptance behavior about reception type on health-food-life information-providing in personal-target type through Q-analysis ; to propose a developmental suggestion about it.\n",
      "\n",
      "스마트시티 데이터허브를 활용한 공조시스템용 에너지소비량 절감 알고리즘 개발\n",
      "공기조화시스템은 건물 내 공기의 질을 이용자들의 활동에 쾌적하도록 유지해주는 기술 일체를 뜻한다. 대형 건축물의 중앙식 공조시스템은 미리 설계된 매뉴얼에 맞추어 단순하게 운영되기에, 건물에너지의 낭비를 초래하고, 실내 공기질 개선 등 이용자의 요구사항 반영에도 난점을 지닌다. 다양한 도시 데이터를 바탕으로 시민 삶의 질 향상을 목표로 하는 스마트시티와 데이터허브의 도입은 기존 공기조화시스템 개선의 동력이 될 수 있다. 본 논문은 페르소나 기법을 활용하여 테스트 건물인 서울대학교 시흥캠퍼스 교육협력동 이용자들의 니즈를 파악하고, 스마트시티 데이터허브의 데이터를 활용하는 공조시스템 실시간 운영 알고리즘을 제시한다. 알고리즘은 건물 내외 이산화탄소 농도, 미세먼지 농도, 온습도를 비교하여 공조시스템의 댐퍼 개도를 실시간으로 조절한다. 새로운 알고리즘은 공조시스템의 연간 에너지소비량을 기존 대비 32% 절감하고, 실내 미세먼지 및 이산화탄소 농도 또한 이용객의 쾌적 활동범위에서 유지한다.\n",
      "\n",
      "The HVAC system maintains the quality of air in the building to be comfortable for the inhabitants. As the HVAC system for large buildings has usually been operated manually, it has weaknesses in efficient use of energy and reflecting inhabitants’ needs such as air quality improvement. Development of smart city and data hubs, aimed at improving the quality of life of citizens based on various city data, can become a driving force in improving the conventional HVAC system. By using the persona technique, this paper identifies the needs of inhabitants of the test-bed building in Seoul National University and suggests algorithm that run the HVAC system in real-time using data collected through the smart city data hub. The algorithm is designed to adjust the damper position of the HVAC system real-time by comparing the levels of carbon dioxide, fine dust, and temperature and humidity inside and outside the building. Simulation results show that the new HVAC system saves 32% in annual energy consumption compared to the previous system and maintains the concentration of fine dust and carbon dioxide within the range of conditions that allow occupants to comfortably carry out activities.\n",
      "\n",
      "IQR알고리즘의 사분범위 조정을 활용한 당뇨 예측 방법\n",
      "본 논문에서는 당뇨병을 조기진단 및 예측하기 위해 머신러닝에 사용되는 당뇨데이터를 전처리하는 방법을 제안한다. 전처리 방법에는 의료데이터의 대표적인 문제인 결측치, 이상치, 클래스의 불균형문제를 포함하고 있다. 특히 이상치문제를 해결하기 위해 대표적으로 사용되는 IQR알고리즘은 데이터의 격차가 클 경우, 많은 양의 데이터를 이상치로 간주하기 때문에 본 논문에서는 기존의 IQR알고리즘이 아닌 알고리즘 내의 사분범위를 조정하여 입력데이터에 적합한 이상치제거 알고리즘을 제안하였다.결측치 및 클래스의 불균형 문제는 중앙값과 SMOTE알고리즘을 사용하여 문제를 해결하였다. 제안하는 전처리 방법을 사용하였을 경우, 기존의 이상치 알고리즘을 적용한 결과보다 5%의 우수한 성능을 나타내었으며, 또한 AUC수치 역시 4% 더 높은 성능을 보이고 있다.\n",
      "\n",
      "In this paper, a method of pretreatment of diabetes data used in machine learning is proposed to diagnose and predict diabetes early. The preprocessing methods include missing values, abnormal values, and level imbalance, which are representative problems in medical data. In particular, the IQR algorithm, which is used to solve the ideal value problem, considers a large amount of data as ideal value when the data gap is large, so this paper proposes an ideal value elimination algorithm suitable for input data. The median and SMOTE algorithms are used to solve the problem of missing values and grade imbalance. The proposed pretreatment method shows 5% better performance than the previous ideal value algorithm, and the AUC value is also 4%.\n",
      "\n",
      "남극 환경에서 다중 로봇 시스템을 위한 최근접 이웃 알고리즘 기반 효율적 다중 작업 스케줄링\n",
      "This paper addresses the problem of multi-robot task scheduling in Antarctic environments. It is difficult to operate multiple robots in Antarctic environments due to the icy ground condition and the lack of powers. In our previous work, the multi-robot task scheduling in Antarctic environments has been solved using ant colony optimization. Although it worked successfully, it caused much computation time. This paper proposes an efficient multi-robot task scheduling approach using nearest neighbor algorithm in Antarctic environments. The proposed method was tested in both simulated environments and Antarctic environments. The proposed method showed better performance in terms of computation time and cost than ant colony optimization and genetic algorithm.\n",
      "\n",
      "UAV 지원 Cellular-connected 시스템에서 Position Fingerprint Database를 이용한 협력적 빔 선택 알고리즘\n",
      "UAV (Unmanned Aerial Vehicle)는 높은 고도와 이동성의 특징 때문에, 지상 네트워크의 한계를 넘을 수 있어 NR (New Radio) 시스템의 핵심 요소로 주목받고 있다. 하지만 높은 고도의 UAV는 높은 LOS (Line-Of-Sight) 확률로 다른 셀 간 간섭의 영향을 크게 받을 수 있다. 이에 본 논문에서는 간섭의 영향을 줄이고, 전송 효율을 최대화할 수 있도록 최적의 빔을 선택하는 알고리즘을 제안한다. 제안 알고리즘은 크게 두 단계로 구성된다. 본 논문에서 제시한 사용자 타입에 맞게 필요한 정보를 저장하는 사용자 위치 기반 핑거프린트 데이터베이스 (Fingerprint Database)를 구축하는 과정과 협력적 빔 선택 과정으로 나뉜다. 성능 분석을 위해 셀룰러 협력 다운링크 시스템을 기반으로 모의실험을 진행하였고, 성능 분석 지표로는 신호 대 간섭 및 잡음 비율의 누적 분포 함수 (SINR CDF, Signal-to-Interference-plus-Noise Ratio Cumulative Distribution Function)와 스펙트럼 효율의 누적 분포 함수 (SE CDF, Spectral Efficiency Cumulative Distribution Function)를 사용하였다. 성능 분석 결과 제안 알고리즘이 간섭의 영향은 줄이고, 원하는 신호의 성능은 높인다는 점을 확인하였다. 또한, 정보 교환에 필요한 자원의 양을 줄임으로써 오버헤드 및 시스템의 비용을 고려한 효율적인 알고리즘이 될 수 있음을 확인하였다.\n",
      "\n",
      "Due to its high altitude and mobility characteristics, unmanned aerial vehicle (UAV) is attracting attention as a key element of new radio (NR) systems as they can exceed the limits of terrestrial networks. However, high line-of-sight (LOS) probability due to high altitude can be greatly affected by interference between different cells. Accordingly, this paper proposes an algorithm that select optimal beam to reduce the impact of interference, and maximize transmission efficiency. The proposed algorithm consists largely of two steps. According to the user type presented in this paper, it is divided into a process of constructing a user position-based fingerprint database and a process of cooperative beam selection process. Simulations were conducted based on cellular cooperative downlink systems for performance analysis, and signal-to-interference-plus-noise cumulative distribution function (SINR CDF) and spectral efficiency cumulative distribution function (SE CDF) were used as performance analysis indicators. As a result of performance analysis, it was confirmed that the proposed algorithm can reduce the effect of interference and increase the performance of the desired signal. Also, it was confirmed that it is an efficient algorithm that considers overhead and system costs by reducing the amount of resources required for information exchange.\n",
      "\n",
      "계산 광학 현미경: 알고리즘을 이용한 영상 복원 기술\n",
      "Like a mobile phone camera, optical microscopy typically relies on optical lenses that convert a plane wave to a spherical wave or vice versa. In such conventional imaging scheme, light from an object point propagates through a set of lenses and creates a tight focus on a camera, resulting in 1 to 1 relation between the object point and the camera pixel. Recently, this conventional imaging paradigm has been challenged by a new paradigm where computational algorithms replace the role of lenses. Here, I will introduce the concept of computational optics and some novel microscopy techniques based on algorithms.\n",
      "\n",
      "센서 데이터 기반의 타이어 상태진단 알고리즘 개발\n",
      "Purpose: Tire maintenance is essential for safety, as tire failure can cause significant damage to human health and infrastructure during light rail operations. Therefore, we developed a diagnostic algorithm for light rail rubber tires to prevent such catastrophic events.\n",
      "Methods: Vibration signals measured by tri-axis accelerometers were acquired during real-world light rail operation, and we compared vibrations among various tire states, established a health index, and developed a model for determining tire state.\n",
      "Results: The most important type of vibration in terms of tire state was x-axis vibration. Our model determined tire states by calculating x-axis vibration differences in various tire conditions. Furthermore, high model accuracy was confirmed by stratified k-fold cross-validation.\n",
      "Conclusion: Our diagnostic algorithm for determining tire condition reduces operating and support costs and promotes reliability and safety by enabling timely and appropriate maintenance that considers the age of individual tires. Thus, it could replace existing time-based maintenance protocols.\n",
      "\n",
      "Depth Camera와 GPS를 활용한 실시간 객체 좌표 생성 알고리즘 개발\n",
      "뎁스 카메라를 이용한 다양한 연구가 많이 발전하고 있다. 본 논문은 이러한 추세에 발맞춰 뎁스 카메라와 RGB 카메라를 동시에 이용하여 실시간 물체의 GPS UTM 좌표를 찾는 연구를 수행했다. 먼저 해상도가 다른 두 카메라의 해상도 매칭을 수행한 후, RGB 카메라와 인식된 물체의 경계 상자의 중앙 픽셀 좌표를 사용해 객체 인식을 한다. 그 후, 카메라로부터 객체까지의 거리를 같은 픽셀로 해상도를 맞춘 뎁스 카메라를 사용해 측정했다. 카메라 픽셀의 초점, 객체 경계 상자의 중심 픽셀 좌표, 뎁스 카메라로 구한 거리를 통해 카메라에서 객체까지의 X, Y 거리를 계산했다. 그런 다음 카메라와 같은 위치에 있는 GPS의 UTM 좌푯값, GPS의 이전 좌표를 통해 추출된 방향, 카메라가 얻은 객체로부터 떨어진 X, Y 거리 등을 계산해 계산된 값을 측정했다. 실험 결과의 정확성을 위해 GPS를 통해 특정 지점의 거리와 UTM 좌표를 미리 구한 뒤 실제 사람이 그 위치에 서서 객체를 인식뒤 정확도를 판단했다. 실험 결과, 10m 이내에서 높은 정확도의 결과를 얻었다.\n",
      "\n",
      "Various studies using depth cameras are developing a lot. In line with the trend, this paper conducted a study to find GPS UTM coordinates of real-time objects using a camera with a depth camera and an RGB camera at the same time. After first performing resolution matching of two cameras with different resolutions, we find out object recognition using RGB cameras and central pixel coordinates of the bounding box of the recognized object. After that, the distance from the camera to the object was measured using a depth camera that matched the resolution with the same pixel. X and Y distances away from the camera to the object were calculated through the focus of the camera pixel, the center pixel coordinates of the bounding box of the object, and the distance obtained by the depth camera. Then, the calculated value was calculated by the UTM coordinate value of GPS in the same position as the camera, the heading direction extracted through the previous coordinates of GPS, and the X and Y distances away from the object obtained by the camera. For the accuracy of the experimental results, the distance and UTM coordinates of a particular point were obtained in advance through GPS, and then a real person stood at the location and recognized the object, and then the accuracy was determined. As a result of the experiment, a result with high accuracy was obtained within 10m.\n",
      "\n",
      "고해상도 단순 이미지의 객체 분류 학습모델 구현을 위한 개선된 CNN 알고리즘 연구\n",
      "CNN(Convolutional Neural Network) 알고리즘은 인공신경망 구현에 활용되는 대표적인 알고리즘으로 기존 FNN(Fully connected multi layered Neural Network)의 문제점인 연산의 급격한 증가와 낮은 객체 인식률을 개선하였다. 그러나 IT 기기들의 급격한 발달로 최근 출시된 스마트폰 및 태블릿의 카메라에 촬영되는 이미지들의 최대 해상도는 108MP로 약 1억 8백만 화소이다. 특히 CNN 알고리즘은 고해상도의 단순 이미지를 학습 및 처리에 많은 비용과 시간이 요구된다. 이에 본 논문에서는 고해상도 단순 이미지의 객체 분류 학습모델 구현을 위한 개선된 CNN 알고리즘을 제안한다. 제안하는 알고리즘은 고해상도의 이미지들의 학습모델 생성 시간을 감소하기 위해 CNN 알고리즘의 풀링계층의 Max Pooling 알고리즘 연산을 위한 인접 행렬 값을 변경한다. 변경한 행렬 값마다 4MP, 8MP, 12MP의 고해상도 이미지들의 처리할 수 있는 학습 모델들을 구현한다. 성능평가 결과, 제안하는 알고리즘의 학습 모델의 생성 시간은 12MP 기준 약 36.26%의 감소하고, 학습 모델의 객체 분류 정확도와 손실률은 기존 모델 대비 약 1% 이내로 오차 범위 안에 포함되어 크게 문제가 되지 않는다. 향후 본 연구에서 사용된 학습 데이터보다 다양한 이미지 종류 및 실제 사진으로 학습 모델을 구현한 실질적인 검증이 필요하다.\n",
      "\n",
      "A convolutional neural network (CNN) is a representative algorithm for implementing artificial neural networks. CNNs have improved on the issues of rapid increase in calculation amount and low object classification rates, which are associated with a conventional multi-layered fully-connected neural network (FNN). However, because of the rapid development of IT devices, the maximum resolution of images captured by current smartphone and tablet cameras has reached 108 million pixels (MP). Specifically, a traditional CNN algorithm requires a significant cost and time to learn and process simple, high-resolution images. Therefore, this study proposes an improved CNN algorithm for implementing an object classification learning model for simple, high-resolution images. The proposed method alters the adjacency matrix value of the pooling layer\"s max pooling operation for the CNN algorithm to reduce the high-resolution image learning model\"s creation time. This study implemented a learning model capable of processing 4, 8, and 12 MP high-resolution images for each altered matrix value. The performance evaluation result showed that the creation time of the learning model implemented with the proposed algorithm decreased by 36.26% for 12 MP images. Compared to the conventional model, the proposed learning model\"s object recognition accuracy and loss rate were less than 1%, which is within the acceptable error range. Practical verification is necessary through future studies by implementing a learning model with more varied image types and a larger amount of image data than those used in this study.\n",
      "\n",
      "여론조사와 빅 데이터를 융합한 예측 알고리즘 개발과 선거적용에 관한 연구\n",
      "2016년 미국 대통령 선거에서 대부분의 미국 여론조사 기관들은 힐러리 클린턴이 오차범위 밖에서 당선될 것을 예측했으나 결과적으로 도널드 트럼프가 대통령으로 당선되었다. 최근 한국에서도 선거 여론조사 결과가 조사기관 사이에 차이가 커서 불신을 받고 있으며 이를 보완할 새로운 방법이 필요하다. 선거 여론조사가 불신을 받는 원인으로는 제한된 표본의 수, 다양한 데이터 수집방법, 특정한 연령구간에 응답이 부족할 때 사용하는 보정기법으로 추정된다. 이 연구에서는 여론조사 결과에 포털 서비스, 블로그, 트위터, 인스타그램 등에서 후보자를 언급한 버즈량을 시간을 변수로 가중치를 부가하여 결합하며 여기에 검색어와 댓글의 긍·부정 반응을 점수를 가감하는 후처리 기법으로 선거결과를 예측하는 알고리즘을 개발한다. 성능평가를 위해 개발된 알고리즘을 지난 한국 대통령 선거 4개월 동안에 적용한다. 선거운동 기간에는 바로 다음 주 여론조사를 예측하고 투표일에는 대통령 당선자와 득표율을 예측하고 오차를 기존의 여론조사들과 비교, 분석한다.\n",
      "\n",
      "A lot of polling organizations predicted Hillary Clinton would win in 2016 USA presidential election over margin of error, though as a result, Donald Trump won. In Republic of Korea supplementary method should be found as many people distrust the opinion polls due to large deviation errors across survey organizations. Limited number of samples, too diverse data acquisition methods and correction techniques for lack of data at a certain age are the likely causes. This research develops a algorithm combining two different data sets, not only opinion poll but also buzz data from Internet portal services, blogs, Twitter and Instagram. These two are combined with assigning weighted values based upon time parameter. To enhance prediction reliability, adjustment technique using positive-negative scoring through figuring out search words and comments in SNS was post-processed as well. To evaluate prediction accuracy it is evaluated during four month Korea presidential election campaign. The prediction results are compared to the next the week opinion poll during campaign. At vote day this predicted the president-elect, and prediction errors to actual votes are computed and analysed, finally.\n",
      "\n",
      "킥보드 불법 주차 문제 해결을 위한 도착지 중심 스테이션 증설 알고리즘\n",
      "본 연구는 공유 전동 킥보드 불법 주차 문제를 해결하고 서비스 품질을 개선하기 위하여 새로운 스테이션 선정 알고리즘을 제안하는 것을 목표로 한다. 최근 도시 교통 문제의 해결 방안으로 대중교통과 최종 목적지를 연결하는 퍼스트-라스트 마일 수단으로 공유 전동 킥보드가 주목받고 있다. 그에 따라 공유 전동 킥보드 시장도 급속도로 성장하면서 그로 인한 문제 또한 심화되고 있다. 이에 본 연구에서는 문제의 본질을 파악하기 위해 텍스트 데이터를 수집하여 ‘LDA 토픽 모델링’으로 공유 킥보드에 관한 이슈를 보행자와 이용자 관점에서 살펴보고 이를 바탕으로 스테이션 증설 알고리즘을 마련하려 한다. 기존에 이미 일부 주차장이 설치되어 있지만 기존의 주차장 위치는 실제 견인 다발 지역과 불일치한다. 따라서 본 연구에서는 ‘서울특별시 전동 킥보드 견인 현황’ 데이터와 여러요인을 반영하여 DBSCAN을 통한 1차 클러스터링 후, K-means를 적용하는 혼합형 클러스터링 기법으로 실제 견인 밀도가 높은 곳에 스테이션을 설치할 수 있는 알고리즘을 제안한다.\n",
      "\n",
      "In this paper, we propose a new station selection algorithm to solve the illegal parking problem of shared electric scooters and improve the service quality. Recently, as a solution to the urban transportation problem, shared electric scooters are attracting attention as the first and last mile means between public transportation and final destinations. As a result, the shared electric scooter market grew rapidly, problems caused by electric scooters are becoming serious. Therefore, in this study, text data are collected to understand the nature of the problem, and the problems related to shared scooters are viewed from the perspective of pedestrians and users in ‘LDA Topic Modeling’, and a station extension algorithm is based on this. Some parking lots have already been installed, but the existing parking lot location is different from the actual area of tow. Therefore, in this study, we propose an algorithm that can install stations at high actual tow density using mixed clustering technology using K-means after primary clustering by DBSCAN, reflecting the ‘current state of electric scooter tow in Seoul’.\n",
      "\n",
      "Levenshtein Distance를 활용한 문자열 유사도 기반의 BIM 속성정보 CFD 매칭 알고리즘\n",
      "For attribute data matching between BIM and CFD, this study proposed a BIM attribute information matching algorithm based on string similarity using levenshtein distance. Considering the versatility of BIM and CFD models, algorithms were developed for IFC and OpenFOAM, which are open-source technologies. The algorithm consists of three modules. First of all, BIM attribute data extraction algorithm was established to extract attribute information from BIM. In addition, in order to input CFD of accurate property information, a database of property information on building materials was established. To implement a matching algorithm based on string similarity, the levenshtein distance algorithm, which calculates the editing distance between two strings, was applied. A matching algorithm was designed to convert the edit distance to similarity and input the attribute data of the selected optimal material to the CFD model. The attribute data of the material with the highest degree of similarity was input into the CFD model. Validation of the developed algorithm was conducted to evaluate the accuracy. As a result of validation, the BIM attribute information extraction algorithm was evaluated with an accuracy of about 99.1%. The matching algorithm accurately matched all materials belonging to the IFC to the CFD model. Therefore, the accuracy of the algorithm proposed in this study was validated.\n",
      "\n",
      "CMA-ES/SPGD 이중 알고리즘을 통한 결맞음 빔 결합 시스템 위상제어 및 동작성능에 대한 전산모사 분석\n",
      "본 연구에서는 다채널 결맞음 빔결합 시스템을 위한 위상제어 방식으로 covariant matrix adaption evolution strategy (CMA-ES) 알고리즘 및 stochastic parallel gradient descent (SPGD) 알고리즘을 결합한 이중 위상제어 알고리즘을 제안하고 그 동작 특성을 전산모사를 통해 분석한다. 제안하는 CMA-ES/SPGD 이중 위상제어 알고리즘은 결합된 최종 출력광 세기가 미리 설정된 특정값에 도달하기 전까지는 그 위상제어 최적화를 CMA-ES 알고리즘을 통해 진행하고, 그 이후에는 SPGD 알고리즘으로 전환하여 진행하는 순차적 이중 구조를 취한다. 이를 이상적인 7채널과 19채널 광섬유 결합기 기반 결맞음 빔결함 시스템에 적용하였을 때, 위상제어 최적화 평균 수렴시간이 기존의 SPGD 알고리즘만 단독적용한 경우에 비해 약 10% 단축됨을 확인하였다. 뿐만 아니라, 동일한 결맞음 빔결함 시스템에서 실제 환경과 유사하게 각 채널광에 위상잡음을 부가적으로 인가한 경우, 본 연구에서 제안하는 이중 위상제어 알고리즘을 적용할 경우 주어진 조건에서 그 평균 수렴시간이 기존의 SPGD 알고리즘만 단독적용한 경우에 비해 7채널 시스템의 경우 약 17%, 19채널 시스템의 경우 약 16–27% 정도 단축됨을 확인하였다. 본 연구에서 제안한 CMA-ES/SPGD 이중 위상제어 알고리즘은 향후 실제 대기 환경과 같이 위상잡음 효과를 무시할 수 없는 조건에서 결맞음 빔결합을 구현시 매우 유용하게 활용될 수 있을 것으로 기대된다.\n",
      "\n",
      "In this study, we propose a hybrid phase-control algorithm for multi-channel coherent beam combining (CBC) system by combining the covariant matrix adaption evolution strategy (CMA-ES) and stochastic parallel gradient descent (SPGD) algorithms and analyze its operational performance. The proposed hybrid CMA-ES/SPGD algorithm is a sequential process which initially runs the CMA-ES algorithm until the combined final output intensity reaches a preset interim value, and then switches to running the SPGD algorithm to the end of the whole process. For ideal 7-channel and 19-channel all-fiber-based CBC systems, we have found that the mean convergence time can be reduced by about 10% in comparison with the case when the SPGD algorithm is implemented alone. Furthermore, we analyzed a more realistic situation in which some additional phase noise was introduced in the same CBC system. As a result, it is shown that the proposed algorithm reduces the mean convergence time by about 17% for a 7-channel CBC system and 16–27% for a 19-channel system compared to the existing SPGD alone algorithm. We expect that for implementing a CBC system in a real outdoor environment where phase noise cannot be ignored, the hybrid CMA-ES/SPGD algorithm proposed in this study will be exploited very usefully.\n",
      "\n",
      "세그멘테이션 기반 차선 인식 네트워크를 위한 적응형 키포인트 추출 알고리즘\n",
      "딥러닝 기반의 이미지 세그멘테이션은 차선 인식을 위해 널리 사용되는 접근 방식 중 하나로, 차선의 키포인트를 추출하기 위한 후처리 과정이 필요하다. 일반적으로 키포인트는 사용자가 지정한 임계값을 기준으로 추출한다. 하지만 최적의 임계값을 찾는 과정은 큰 노력을 요구하며, 데이터 세트(또는 이미지)마다 최적의 값이 다를 수 있다. 본 연구는 사용자의 직접 임계값 지정 대신, 대상의 이미지에 맞추어 적절한 임계값을 자동으로 설정하는 키포인트 추출 알고리즘을 제안한다. 본 논문의 키포인트 추출 알고리즘은 차선 영역과 배경의 명확한 구분을 위해 줄 단위 정규화를 사용한다. 그리고 커널 밀도 추정을 사용하여, 각 줄에서 각 차선의 키포인트를 추출한다. 제안하는 알고리즘은 TuSimple과 CULane 데이터 세트에 적용되었으며, 고정된 임계값 사용 대비 정확도 및 거리오차 측면에서 1.80%p와 17.27% 향상된 결과를 얻는 것을 확인하였다.\n",
      "\n",
      "Deep-learning-based image segmentation is one of the most widely employed lane detection approaches, and it requires a post-process for extracting the key points on the lanes. A general approach for key-point extraction is using a fixed threshold defined by a user. However, finding the best threshold is a manual process requiring much effort, and the best one can differ depending on the target data set (or an image). We propose a novel key-point extraction algorithm that automatically adapts to the target image without any manual threshold setting. In our adaptive key-point extraction algorithm, we propose a line-level normalization method to distinguish the lane region from the background clearly. Then, we extract a representative key point for each lane at a line (row of an image) using a kernel density estimation. To check the benefits of our approach, we applied our method to two lane-detection data sets, including TuSimple and CULane. As a result, our method achieved up to 1.80%p and 17.27% better results than using a fixed threshold in the perspectives of accuracy and distance error between the ground truth key-point and the predicted point.\n",
      "\n",
      "AI 기반 수요예측 알고리즘 모바일 모니터링 애플리케이션 설계\n",
      "최근 많은 기업이 다양한 AI 기반 수요예측 알고리즘을 통해서 이익을 창출하기 위해 시스템을 구축하고 있다. 그렇기에 본 연구에서는 AI 수요예측 관련 자료를 사용자가 실시간으로 모니터링 할 수 있는 애플리케이션을 개발하고자 한다. 이 애플리케이션을 만들 때 정보를 쉽게 이해하도록 색채를 용도에 맞춤으로써 도움을 줄 수 있고, 레이아웃을 고려하여 정보를 쉽게 전달하고 한눈에 알아볼 수 있도록 하는 것이 목표이다. 또한, 아이디와 비밀번호 확인, 고유 코드 부분 구성에서 체크 박스 기능과 각 텍스트 기능을 이용하여 설계하였다. 기업별로 정해진 고유 코드를 이용하여 해당되는 기업의 데이터만 확인할 수 있게끔 하여 기밀 데이터 보안성을 강화할 수 있다. 그로 인해 실시간 모니터링을 모바일 애플리케이션으로 보안 문제없이 볼 수 있다.\n",
      "\n",
      "Recently, many companies are building systems to generate profits through various AI-based demand forecasting algorithms. Therefore, this study aims to develop an application that allows users to monitor data related to AI demand prediction in real time. When creating this application, the goal is to help you easily understand the information by adapting the color to the purpose, and to easily convey the information and recognize it at a glance by considering the layout. In addition, the design was constructed using the check box function and each text function in the ID and password verification and the unique code partial configuration. Confidential data security can be enhanced by allowing only the data of the corresponding company to be checked using the unique code set for each company. As a result, real-time monitoring can be viewed without security problems with mobile applications.\n",
      "\n",
      "트랙터 자율주행을 위한 영상 기반 경작지 경계 인식 알고리즘\n",
      "To utilize autonomous driving tractors for precision agriculture, the cultivable farmland area and its boundary information must be determined. Currently, autonomous driving is performed using the global positioning system (GPS) data of four boundary points; however, the operator must drive and obtain the boundary information. In this study, a vision-based autonomous driving algorithm was developed. A stereo camera and a MobileNetV3-based segmentation algorithm were used to segment the cultivable area and boundary, perform autonomous driving, and store the boundary information. Inverse perspective mapping was performed to store the farmland information in a two-dimensional space, and occupancy grid mapping was performed according to the heading angle of the tractor obtained from Inertial Measurement Unit (IMU) and GPS. By using the preview distance concept, a target heading angle of the tractor was generated at a point away from the boundary, and Proportional-Differential controller was used for the path-tracking algorithm.\n",
      "\n",
      "DeepLab V2 기반 실내 시설물 손상 탐지 및 추출 알고리즘\n",
      "This paper proposes an algorithm that displays the damage of main indoor facilities by detecting and extracting information. First, to extract information for each facility structure, a facility segmentation algorithm is implemented by using DeepLab V2. For efficient learning of the network, the pretrained ResNet101 network is used for transfer learning. In addition, the damage extraction algorithm of the indoor facilities is also based on DeepLab V2, the same network structure used in facility segmentation. It is confirmed through a robot experiment that the accuracy of representing the damage information regardless of near and far facilities is greatly improved when the facility segmentation algorithm is used.\n",
      "\n",
      "뇌파정보를 이용한 생체정보 기반의 사용자 인증 알고리즘 연구\n",
      "생체정보는 물리적인 보관이나 사용자의 암기가 필요없기 때문에 도난·도용·양도가 불가능하다는 점에서 대안 인증수단으로 주목받고 있다. 그러나 개인의 생체정보에 대한 프라이버시 문제와 다양하지 못한 생체정보를 사용하기 때문에 재전송 공격에 취약한 문제점을 가지고 있다. 또한 시간 차이에 따른 뇌파 신호의 차이가 있어 인증 정확도가 낮다는 문제점을 가지고 있다. 이러한 문제점을 해결하기 위해 뇌파 정보를 이용한 사용자 인증 알고리즘을 제안하고, 단채널 뇌파정보 측정 장치를 이용하여 대역별 사인파와 특징점을 추출하여 상호유사도 기반의 연관 관계를 성립하여 뇌파정보를 이용한 인증 알고리즘을 개발한 후, 사용자별 뇌파정보 처리 기술을 개발하였다. 그리고 FIDO 환경에서 사용가능한 EEG 신호를 이용한 인증 모델을 보안코드를 이용하여 생성된 문자열을 사용자가 인식했을 때, 발생하는 EEG 신호를 이용하여 사용자를 인증하는 방법 정립하였다. 제안 방법에서는 단채널 EEG 디바이스를 이용하여 특정 파형의 비율의 차이를 검증함으로써 기존 다채널 EEG 디바이스를 이용한 주파수 파워를 이용하는 방법보다는 편리한 방법을 제공하고 해당 정보를 기존 생체 인증 시스템에 전달할 수 있어 활용성을 높였다.\n",
      "\n",
      "Biometric information is attracting attention as an additional or alternative authentication method to existing authentication methods such as passwords and public certificates in that it does not require separate storage and memorization, has no risk of loss, and cannot be stolen or transferred. However, privacy issues due to leakage of personal information And since fixed biometric information is used, it has a problem of being vulnerable to retransmission attack. In addition, there is a problem in that the authentication accuracy is low because there is a difference in the EEG signal according to the time difference. To solve this problem, we propose a user authentication algorithm using EEG information. Using a single-channel EEG information measuring device, sine waves and feature points for each band were extracted to establish a correlation based on mutual similarity, an authentication algorithm using EEG information was developed, and an EEG information processing technology for each user was developed. In addition, a method of authenticating a user using an EEG signal generated when a user recognizes a string generated by using a security code in an authentication model using an EEG signal usable in a FIDO environment was established. The proposed method uses a single-channel EEG device to verify the difference in the ratio of a specific waveform (Theta/Alpha), providing a more convenient method than the method using frequency power using an existing multi-channel EEG device, and providing the information to the existing biometric authentication system. Because it can be delivered to, the usability has been increased.\n",
      "\n",
      "라이다 기반 종합관제 플랫폼 구축을 위한 오버레이 멀티캐스트 알고리즘 설계\n",
      "안전한 자율주행에 필요한 정보를 더 많이 확보하여 안전성을 강화하고 다양한 서비스를 도입하기 위해 도로 사용자들 사이에 실시간으로 정보를 공유할 수 있는 통신기술이 개발되고 있다. 이러한 데이터는 관제 시스템에 실시간으로 수집되고 공유되면 다양한 형태의 진보한 서비스가 개발되고 유용하게 활용될 것이다. 본 논문은 라이다 기반 종합관제 플랫폼을 구축하기 위한 방안을 연구하였다. 그 과정에서 DSR (Dynamic Source Routing) 프로토콜 기반의 자율주행 차량의 라이다센서 시스템, RSU(Road Side Unit)에 장착된 인프라센서 시스템, 에지 관제시스템, 그리고 종합관제 시스템의 실시간 정보공유에 적합한 오버레이 멀티캐스트 프로토콜을 제안하였다. 기존의 MST (Minimum Spanning Tree) 알고리즘을 개선하여 특정 노드에 집중되는 분기를 줄이는 BAMST (Branch Aware Minimum Spanning Tree) 알고리즘을 제시하고 MATLAB 성능평가를 통하여 이를 확인하였다.\n",
      "\n",
      "Communication technology that can interconnect to road users is being developed to secure more information necessary for safe autonomous driving, enhance safety, and introduce various services. When these data are collected and shared in real time with the control system, various types of advanced services will be developed and utilized. In this paper, a method to build a lidar-based comprehensive control platform was studied. In the process, the DSR (Dynamic Source Routing) protocol-based lidar sensor system of autonomous vehicles, the infrastructure sensor system mounted on the RSU (Road Side Unit), the edge control system, and the overlay multi system suitable for real-time information sharing of the comprehensive control system A cast protocol was proposed. The BAMST (Branch Aware Minimum Spanning Tree) algorithm, which improves the existing MST (Minimum Spanning Tree) algorithm to reduce branching focused on a specific node, was proposed and confirmed through MATLAB performance evaluation.\n",
      "\n",
      "딥러닝 알고리즘을 이용한 태양광발전량 예측 모델에 대한 연구\n",
      "본 논문에서는 태양광에너지에 대한 발전량을 예측하기 위하여 3가지 딥러닝 알고리즘을 적용하였고, 실제 한국전력거래소에서 사용하고 있는 예측오차율을 통해 발전량을 예측오차를 산출하였다. 태양광발전설비와 기상청의 데이터 중 주요 데이터를 추출하고 파라미터를 최적화를 진행하였다. 3가지 알고리즘 중, 공통적으로 LSTM(Long Short-Term Memory) 알고리즘이 우수한 특성을 나타내었고, 구름과 같이 기상 환경이 변하는 경우에는 실제 발전량과 예측 발전량 사이에 오차가 많이 발생였지만 일정하게 기상이 유지될 경우에는 예측발전량이 실제 발전량에 수렴하는 특징을 보였다. 이러한 결과를 통해 태양발전시스템은 다양한 환경에 따른 출력특성 학습을 통해 예측발전과 실제 발전사이의 예측 오차율을 개선할 수 있을 예상된다.\n",
      "\n",
      "In this paper, in order to predict the amount of power generation for solar energy, the prediction error rates for three deep learning algorithms were applied and tested. For the data used during the test, the parameters were optimized by extracting data from photovoltaic power generation facilities and Korea Meteorological Administration. Among the three algorithms, as a result of measuring the prediction error rate according to the weather environment, the LSTM(Long Short-Term Memory) algorithm showed excellent characteristics in common. When the meteorological environment changes, such as clouds, there is a large error between the actual power generation and the predicted power generation. In addition, when the weather is maintained at a constant level, the predicted power generation converges to the actual power generation. Through these results, it is thought that the prediction error rate between predicted power generation and actual power generation can be improved through learning of output characteristics according to various environments.\n",
      "\n",
      "자율주행 이앙기를 위한 모 심은 영역의 영상처리 및 딥러닝 기반 인식 알고리즘\n",
      "When the global positioning system (GPS) signal is poor, GPS-based autonomous driving rice transplanters often drive over areas where seedlings have already been planted. To solve this problem, in this paper, an algorithm was proposed to distinguish planted fields by using deep learning (DL) and red-green-blue (RGB) images. The differences between the learning data and the test data, referred to as the domain gap, must be reduced. To reduce the domain gap, three methods were used in this study: domain randomization, domain normalization, and style blend. The DL model provided information regarding locations where seedlings have been planted. Next, to control the rice transplanter autonomously, a linear boundary between the cultivated and un cultivated areas was established using the RANSAC algorithm. Finally, inverse-perspective mapping was performed to obtain the bird’s eye view, which was then used to obtain the desired steering angle command of the rice transplanter.\n",
      "\n",
      "다자유도 갠트리형 용접로봇 시스템의 최적모션 생성을 위한 벡터 방정식 알고리즘 기초 연구\n",
      "This paper is a basic study for the development of a simulator algorithm to generate optimal robot motion and path planning for a multi-D.O.F(Degree of Freedom) gantry-type welding robot system. The main idea of the simulator algorithm is to utilize vector equations to define the relationship between each frame derived by forward kinematics. Eight objective functions were defined using vector equations that define the relationship between frames, and each was formulated as an optimization problem. For the optimization problem, the optimal value was derived through optimizers such as SQP (Sequential Quadratic Problem), Active-set, and fgoalattain, and motion and error range were simulated by putting the derived control variables into a forward kinematics simulator. If a specific motion can be created through various formalized optimization problems, it is expected that it can be used as a policy for reinforcement learning in the future.\n",
      "\n",
      "웨이블릿 변환 특징량 추출 방법을 적용한 DC 계통 지능형 고장진단 알고리즘\n",
      "DC grids are being considered for renewable energy connection and underwater power transmission. There are overcurrent-based methods and methods using frequency thresholds as fault diagnosis methods currently used in DC systems. However, since the fault current is affected by the ground impedance, it may be difficult to accurately diagnose the fault with the conventional method in the case of HIF. In addition, it is difficult to expect high accuracy when diagnosing a fault location because the ground impedance value varies depending on the weather and season. Therefore, this study proposes an AI-based fault detection algorithm. When a fault occurs in a DC system having a ripple component connected to a rectifier, it has a different frequency pattern depending on the fault location. In this study, a ground fault was simulated through MATLAB Simulink and the fault signal was analyzed in the time and frequency domains. Based on the analysis results, the fault current was wavelet transformed to train the DNN. Then, the model was validated through additional fault data and HIF failures.\n",
      "\n",
      "인공신경망을 이용한 메자닌 상품의 행사 알고리즘\n",
      "메자닌 상품은 채권과 주식의 성격을 모두 가진 금융 투자 상품인데 주로 등급이 낮은 회사가 유동성을 확보하기 위해 금융시장에서 발행한다. 따라서 메자닌 상품에 투자하는 사채권자들은 해당 회사가 발행하는 메자닌 상품에 투자하면 주식으로 전환하는 여부와 함께 주식으로 전환하고자 하는 시점에 대해서 의사결정을 해야 한다. 예컨대 메자닌 상품의 투자자와 발행회사는 투자자의 전환권 행사 여부와 시점에 대한 의사결정 문제가 가장 중요한데 이를 위한 투자 판단 지표가 매우 부족하므로 직관적이거나 정성적인 판단에 의존할 수밖에 없다. 따라서 본 논문에서는 주요 업종별 주식 전환 행사가 완료된 총 2,000개의 학습 데이터와 200개의 예측 실험 데이터로 구분하고 인공신경망 모델을 통해서 메자닌 행사 알고리즘을 설계하고 성능을 분석한다. 본 주제는 금융 분야에서 관심이 높은 메자닌 상품 행사의 난제를 인공신경망 기술을 적용하여 과학적으로 해결하는 방법론을 제안했다는 점에서 그 의의를 갖는다.\n",
      "\n",
      "Mezzanine products are financial investment products with both bond and stock characteristics, which are mainly issued by low-grade companies in the financial market to secure liquidity. Therefore, bondholders investing in mezzanine products must make decisions about when they want to convert to stocks, along with whether they invest in mezzanine products issued by the company. Therefore, in this paper, a total of 2,000 learning data and 200 predictive experimental data with stock conversion events completed by major industries are divided, and mezzanine event algorithms are designed and performance analyzed through artificial neural network models. This topic is meaningful in that it proposed a methodology to scientifically solve the difficulties of exercising mezzanine products, which are of high interest in the financial field, by applying artificial neural network technology.\n",
      "\n",
      "3상 PWM 컨버터의 계통 리액터 위치에 무관한 상전압 측정 PLL 제어 알고리즘\n",
      "This paper presents various control methods to improve the quality of recently developed power conversion equipment. Compared to diode rectifier, voltage-source PWM converter controls input current in an actively manner and is widely used as a stable power conversion device. A control operation characteristic of a conventional PWM converter is identified. The conventional voltage sensing position to derive the control angle of the PWM converter required for system control is complexly installed in the hardware and the weight increases as the capacity increases because the system includes the L filter. In order to compensate for these drawbacks, the proposed system is configured to have the flexibility of the system by changing the voltage sensing position to the input terminal of the converter. At this time, since the existing control angle and phase voltage must be estimated, the phase voltage at the changed position was followed by the power source side using LPF and DSOGI-PLL, and this was compared and confirmed through a simulation.\n",
      "\n",
      "시간적 상관도를 활용한 조건부 대체 알고리즘 성능 개선\n",
      "지상파 방송 환경에서 지상파 UHD 사용자 선택형 입체미디어 서비스를 제공할 때, 비대칭적인 양안 영상의 화질 문제는 항상 대두됐다. 이를 해결하기 위해, 양안 영상의 상관도를 활용한 조건부 대체 알고리즘이 연구된 바 있다. 기존의 알고리즘은 고화질 기준 영상을 시차 보상하여 저화질 부가 영상에 적용하는 방식으로 화질을 개선 시켜왔다. 본 논문은 조건부 대체 알고리즘에 시간적 상관도를 이용하여 더욱 효율적으로 부호화 하는 확장된 알고리즘을 제안한다. 이전 시각에 이미 보상되어 복원된 고화질의 부가 영상을 이용해, 현재 시각의 저화질 부가영상을 움직임 보상한다. 제안하는 알고리즘은 이전 알고리즘에 비해 실사 및 애니메이션 540P, 1080P 클립에 대해 각각 평균 30.5%, 19.8% 의 개선된 비트 절감율을 보였다.\n",
      "\n",
      "When providing fixed/mobile broadcast convergence 3DTV services in a terrestrial broadcasting environment, the problem of image quality of asymmetric binocular images has always emerged. To solve this problem, a conditional replenishment algorithm using the correlation of binocular images has been studied. Existing algorithms have improved image quality by compensating the high-definition reference image in a parallax manner and applying it to the low-definition additional image. This paper proposes an extended algorithm that uses temporal correlation to encode conditional replenishment algorithms more efficiently. By using a high-definition additional image that has already been compensated and restored at the previous time, motion compensation is performed on the low-definition additional image of the present time. The proposed algorithm showed Bit saving performance of 19.8% and 30.5% on average for real-film and animation clips 540P and 1080P clips, respectively, compared to previous algorithms.\n",
      "\n",
      "단상/삼상 계통 전력 품질 평가를 위한 고조파 분석 알고리즘 개발\n",
      "With the development of technology, a new class of smaller and more sensitive electrical systems have emerged, requiring higher quality power system. Improving the quality of the power system requires removing harmonics as much as possible to ensure better efficiency. We should first collect information on what harmonic frequencies are included in the current power system to remove the harmonics. In this paper, a new frequency analysis algorithm is introduced for a three-phase and a 1-phase power system. MTE PRS 600.3 is used to generate any harmonics to ensure that the algorithm performs well. Typing any harmonics on the Windows GUI program shows the analyzed result from the board developed for the algorithm.\n",
      "\n",
      "심층 강화학습 기반 적응적 SAR 이미지 필터링 알고리즘 설계\n",
      "Low Earth orbit (LEO) 위성 synthetic aperture radar (SAR)는 지구관측의 효율적인 기술로 최근 많은 연구가 진행 중이다. 하지만 LEO 위성의 시간 제한적 특성상, SAR 원본 이미지의 효율적인 처리에 대한 연구는 필수적이다. 본 논문에서는 LEO SAR 이미지의 효율적인 처리를 위한 심층 강화학습 기반 적응형 스페클 잡음 필터링 알고리즘을 제안한다. 제안하는 알고리즘은 버퍼 상태에 따라 필터 크기를 적응적으로 선택하여 제한된 시간에 최대한의 이미지 해상도를 도출한다. 시뮬레이션 결과, 제안하는 알고리즘은 다른 알고리즘과 비교하였을 때 버퍼 상태를 고려하여 최적의 필터 선택을 하는 것을 확인하였다.\n",
      "\n",
      "Low Earth orbit (LEO) satellite synthetic aperture radar (SAR) is an efficient technology for Earth observation, and a lot of research is in progress. However, due to the time-limited property of LEO satellites, research on time-efficient SAR image processing is essential. In this paper, we propose an adaptive speckle noise filtering algorithm based on deep reinforcement learning for efficient processing of LEO SAR images. The proposed algorithm adaptively selects the filter size according to the buffer state to derive the maximum image resolution in a limited time. As a result of the simulation, the proposed algorithm selects the filter size more efficiently according to the buffer state than the method of conventional algorithm.\n",
      "\n",
      "공통 모드 전압 및 THD를 고려한 계통연계형 3레벨 NPC 인버터의 운용 알고리즘 연구\n",
      "A grid-connected 3-level NPC inverter is a power conversion device that connects renewable energy generators, such as photovoltaic or wind turbines to the grid. Although many studies have focused on this inverter, commercializing it requires strictly satisfying various safety and power quality-related standards. Among many standards, leakage current and grid current total harmonic distortion(THD) can be affected by external factors such as installation environment, aging, and grid conditions. Hence, inverter operations that can satisfy these standards need to be explored. In this study a 3-level NPC inverter operation algorithm using the Phase Opposition Disposition-PWM method that can effectively reduce leakage current and switching frequency adjustment to reduce THD effectively has been proposed.\n",
      "\n",
      "강화학습 기반 제어 알고리즘을 통한 시간 지연을 갖는 구조물의 진동 제어 연구\n",
      "The vibration control of a one-degree-of-freedom system was performed in this study using Deep Deterministic Policy Gradient (DDPG), a reinforcement learning method. A delayed control force compared to the target control force is applied to the system due to the dynamic characteristics of an actuator, such as a pneumatic spring. Reinforcement learning is a learning method that finds better behavior by learning by itself according to a reward function that is directly related to the learning goal without using a complex mathematical model for the system. Since the accelerometer is the most commonly used sensor in vibration measurement, we proposed a suitable learning excitation force and compensation function based on the acceleration data. The final learned policy was used to simulate the superior performance of the control force for various external forces. It was found from the numerical simulation that the vibration control based on the DDPG and reinforced learning is effective in suppressing vibrations.\n",
      "\n",
      "YOLOv5 객체인식 알고리즘을 이용한 실시간 마스크 착용 판별 모델 연구\n",
      "no element.\n",
      "\n",
      "차량용 레이더의 실시간 물체 추적을 위한 연산 효율적 알고리즘 연구\n",
      "no element.\n",
      "\n",
      "아파트 단지 빌딩 내에서의 효율적인 택배 배달 알고리즘\n",
      "no element.\n",
      "\n",
      "낙상 사고의 조기 조치를 위한 CW & FMCW 레이다로 넘어지는 동작 판별 후 신고 알고리즘\n",
      "no element.\n",
      "\n",
      "온실에서의 폐열 에너지 활용을 위한 빅데이터 분석 기반 알고리즘 설계\n",
      "no element.\n",
      "\n",
      "선명한 이미지를 위한 딥러닝 기반의 잡음 제거 알고리즘 제안\n",
      "no element.\n",
      "\n",
      "다수의 전기차를 위한 총 비용 경감 충전 알고리즘\n",
      "no element.\n",
      "\n",
      "딥러닝 FPGA 가속기를 사용한 마스크 착용 시 개인 휴대기기를 위한 얼굴 인식 성능 향상 알고리즘\n",
      "no element.\n",
      "\n",
      "딜레이-민감 비디오 스트리밍 서비스를 위한 DQN 알고리즘 연구\n",
      "no element.\n",
      "\n",
      "여행 관련 최적의 동선 설정 알고리즘\n",
      "no element.\n",
      "\n",
      "UWB TWR 기반 삼변 측위 알고리즘에 관한 연구\n",
      "no element.\n",
      "\n",
      "머신러닝 기반 방향탐지 알고리즘 성능 개선 연구\n",
      "no element.\n",
      "\n",
      "양자 저밀도 패리티 검사 부호를 위한 계층적 신뢰 전파 복호 알고리즘\n",
      "no element.\n",
      "\n",
      "Deep Learning 기반 3D CT 영상 내 휴대수하물 위험물 검출 알고리즘 연구\n",
      "no element.\n",
      "\n",
      "앙상블 학습 기반 중이염 자동 진단 알고리즘\n",
      "no element.\n",
      "\n",
      "위성 연결성에 따른 선택적 핸드오버 알고리즘\n",
      "no element.\n",
      "\n",
      "PPG 신호를 기반으로 한 혈압추정 알고리즘 개발\n",
      "no element.\n",
      "\n",
      "신호 변조 방식 분류를 위한 계층적 알고리즘\n",
      "no element.\n",
      "\n",
      "mmWave 기반 스몰 셀 네트워크에서 빔 패턴, 사용자 스케줄링, 전송 전력 할당을 위한 저복잡도 간섭 관리 알고리즘 개발\n",
      "no element.\n",
      "\n",
      "고밀도 네트워크에서 트래픽 예측을 이용한 스몰셀 범위 조정 알고리즘\n",
      "no element.\n",
      "\n",
      "지연 허용 IoET 망에서 지분증명 합의 알고리즘 개선을 위한 안전성(Security) 분석에 관한 연구\n",
      "no element.\n",
      "\n",
      "KREONET-S의 지능적 네트워크 자원 및 전력 관리를 위한 강화학습 알고리즘 적용 및 검증 모델\n",
      "no element.\n",
      "\n",
      "사용자 위치 측위 성능 향상을 위한 오픈소스 프로그램 성능 개선 알고리즘에 대한 연구\n",
      "no element.\n",
      "\n",
      "다중 에이전트 강화학습에서의 앙상블 알고리즘\n",
      "no element.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.dbpia.co.kr/search/topSearch?searchOption=all&query=%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98'\n",
    "browser.get(url)\n",
    "time.sleep(1)\n",
    "pages = browser.find_element(By.ID,\"pageList\")\n",
    "\n",
    "page_list = pages.find_elements(By.TAG_NAME,'a')\n",
    "\n",
    "title = []\n",
    "content = []\n",
    "writer = []\n",
    "detail_url_list = []\n",
    "\n",
    "# 페이지 마다 링크 가져오기\n",
    "for p in range(3):\n",
    "    page_list = pages.find_elements(By.TAG_NAME,'a')\n",
    "    page_list[p].send_keys(Keys.ENTER)\n",
    "    time.sleep(1)\n",
    "    datas = browser.find_elements(By.CLASS_NAME,'thesis__link')\n",
    "    for i in datas:\n",
    "        detail_url = i.get_attribute('href')\n",
    "        detail_url_list.append(detail_url)\n",
    "\n",
    "# 가져온 링크로 제목, 초안 만들기\n",
    "for i in detail_url_list:\n",
    "    browser.get(i)\n",
    "    title.append(browser.find_element(By.ID,'thesisTitle').text)\n",
    "    try:\n",
    "        content.append(browser.find_element(By.CLASS_NAME,'abstractTxt').text)\n",
    "    except:\n",
    "        content.append(\"no element.\")\n",
    "        continue\n",
    "\n",
    "# 총 출력\n",
    "for i in range(len(detail_url_list)):\n",
    "    print(title[i])\n",
    "    print(content[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "print(len(detail_url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(detail_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "StaleElementReferenceException",
     "evalue": "Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000104ca5670 chromedriver + 4298352\n1   chromedriver                        0x0000000104c9dbbc chromedriver + 4266940\n2   chromedriver                        0x00000001048d0758 chromedriver + 280408\n3   chromedriver                        0x00000001048d40c8 chromedriver + 295112\n4   chromedriver                        0x00000001048d3d74 chromedriver + 294260\n5   chromedriver                        0x00000001048d4170 chromedriver + 295280\n6   chromedriver                        0x000000010490c9e0 chromedriver + 526816\n7   chromedriver                        0x000000010490cb90 chromedriver + 527248\n8   chromedriver                        0x0000000104902e20 chromedriver + 486944\n9   chromedriver                        0x00000001048ffb90 chromedriver + 474000\n10  chromedriver                        0x0000000104944080 chromedriver + 753792\n11  chromedriver                        0x00000001048fe2d0 chromedriver + 467664\n12  chromedriver                        0x00000001048ff354 chromedriver + 471892\n13  chromedriver                        0x0000000104c656c4 chromedriver + 4036292\n14  chromedriver                        0x0000000104c69c64 chromedriver + 4054116\n15  chromedriver                        0x0000000104c702d8 chromedriver + 4080344\n16  chromedriver                        0x0000000104c6a970 chromedriver + 4057456\n17  chromedriver                        0x0000000104c418dc chromedriver + 3889372\n18  chromedriver                        0x0000000104c8925c chromedriver + 4182620\n19  chromedriver                        0x0000000104c893b4 chromedriver + 4182964\n20  chromedriver                        0x0000000104c980f4 chromedriver + 4243700\n21  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n22  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m page[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msend_keys(Keys\u001b[39m.\u001b[39mENTER)\n\u001b[1;32m      2\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m page[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49msend_keys(Keys\u001b[39m.\u001b[39;49mENTER)\n\u001b[1;32m      4\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m0.5\u001b[39m)\n\u001b[1;32m      5\u001b[0m page[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msend_keys(Keys\u001b[39m.\u001b[39mENTER)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:231\u001b[0m, in \u001b[0;36mWebElement.send_keys\u001b[0;34m(self, *value)\u001b[0m\n\u001b[1;32m    228\u001b[0m             remote_files\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_upload(file))\n\u001b[1;32m    229\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(remote_files)\n\u001b[0;32m--> 231\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute(\n\u001b[1;32m    232\u001b[0m     Command\u001b[39m.\u001b[39;49mSEND_KEYS_TO_ELEMENT, {\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(keys_to_typing(value)), \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m: keys_to_typing(value)}\n\u001b[1;32m    233\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:404\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    402\u001b[0m     params \u001b[39m=\u001b[39m {}\n\u001b[1;32m    403\u001b[0m params[\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_id\n\u001b[0;32m--> 404\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parent\u001b[39m.\u001b[39;49mexecute(command, params)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py:440\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_executor\u001b[39m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_handler\u001b[39m.\u001b[39;49mcheck_response(response)\n\u001b[1;32m    441\u001b[0m     response[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unwrap_value(response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    442\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf/lib/python3.8/site-packages/selenium/webdriver/remote/errorhandler.py:245\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    243\u001b[0m         alert_text \u001b[39m=\u001b[39m value[\u001b[39m\"\u001b[39m\u001b[39malert\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    244\u001b[0m     \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[39m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[0;32m--> 245\u001b[0m \u001b[39mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[0;31mStaleElementReferenceException\u001b[0m: Message: stale element reference: element is not attached to the page document\n  (Session info: chrome=112.0.5615.137)\nStacktrace:\n0   chromedriver                        0x0000000104ca5670 chromedriver + 4298352\n1   chromedriver                        0x0000000104c9dbbc chromedriver + 4266940\n2   chromedriver                        0x00000001048d0758 chromedriver + 280408\n3   chromedriver                        0x00000001048d40c8 chromedriver + 295112\n4   chromedriver                        0x00000001048d3d74 chromedriver + 294260\n5   chromedriver                        0x00000001048d4170 chromedriver + 295280\n6   chromedriver                        0x000000010490c9e0 chromedriver + 526816\n7   chromedriver                        0x000000010490cb90 chromedriver + 527248\n8   chromedriver                        0x0000000104902e20 chromedriver + 486944\n9   chromedriver                        0x00000001048ffb90 chromedriver + 474000\n10  chromedriver                        0x0000000104944080 chromedriver + 753792\n11  chromedriver                        0x00000001048fe2d0 chromedriver + 467664\n12  chromedriver                        0x00000001048ff354 chromedriver + 471892\n13  chromedriver                        0x0000000104c656c4 chromedriver + 4036292\n14  chromedriver                        0x0000000104c69c64 chromedriver + 4054116\n15  chromedriver                        0x0000000104c702d8 chromedriver + 4080344\n16  chromedriver                        0x0000000104c6a970 chromedriver + 4057456\n17  chromedriver                        0x0000000104c418dc chromedriver + 3889372\n18  chromedriver                        0x0000000104c8925c chromedriver + 4182620\n19  chromedriver                        0x0000000104c893b4 chromedriver + 4182964\n20  chromedriver                        0x0000000104c980f4 chromedriver + 4243700\n21  libsystem_pthread.dylib             0x000000019e5affa8 _pthread_start + 148\n22  libsystem_pthread.dylib             0x000000019e5aada0 thread_start + 8\n"
     ]
    }
   ],
   "source": [
    "page[2].send_keys(Keys.ENTER)\n",
    "time.sleep(0.5)\n",
    "page[1].send_keys(Keys.ENTER)\n",
    "time.sleep(0.5)\n",
    "page[2].send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "플랫폼노동의 알고리즘 현황과 대응방안 – 알고리즘의 공정성과 투명성, 노동자 통제를 중심으로\n",
      "no element.\n",
      "\n",
      "선박 추진용 2행정 저속엔진의 고장모드 데이터 개발 및 LSTM 알고리즘을 활용한 특성인자 신뢰성 검증연구\n",
      "In the 4th industrial revolution, changes in the technological paradigm have had a direct impact on the maintenance system of ships. The 2-stroke low speed engine system integrates with the core equipment required for propulsive power. The Condition Based Management (CBM) is defined as a technology that predictive maintenance methods in existing calender-based or running time based maintenance systems by monitoring the condition of machinery and diagnosis/prognosis failures. In this study, we have established a framework for CBM technology development on our own, and are engaged in engineering-based failure analysis, data development and management, data feature analysis and pre-processing, and verified the reliability of failure mode DB using LSTM algorithms. We developed various simulated failure mode scenarios for 2-stroke low speed engine and researched to produce data on onshore basis test_beds. The analysis and pre-processing of normal and abnormal status data acquired through failure mode simulation experiment used various Exploratory Data Analysis (EDA) techniques to feature extract not only data on the performance and efficiency of 2-stroke low speed engine but also key feature data using multivariate statistical analysis. In addition, by developing an LSTM classification algorithm, we tried to verify the reliability of various failure mode data with time-series characteristics.\n",
      "\n",
      "시분할 다중 접속 기반 무선 메쉬 네트워크에서 브로드캐스트 스케줄링 문제를 위한 타부서치 알고리즘\n",
      "시분할 다중 접속 기반에서 브로드캐스트 스케줄링 문제는 타임 슬롯을 사용하여 모든 단말이 충돌 없이 전송할 수 있도록 설계하는 문제이다. 본 논문에서는 시분할 다중 접속 기반의 무선 메쉬 네트워크에서 브로드캐스트를 사용하는 노드의 전송 스케줄을 최적화하여 전체 전송 횟수와 타임 슬롯 이용률을 최대화하는 브로드캐스트 스케줄링 최적화 알고리즘을 제안한다. 제안된 최적화 알고리즘은 메타휴리스틱 방식 중 하나인 타부서치 알고리즘을 사용한다. 제안된 타부서치 알고리즘은 전체 전송 횟수를 최대화하는 목적함수를 사용하여 효율적인 이웃해 생성방식을 설계하였다. 본 논문에서는 네트워크에서 발생하는 모든 브로드캐스팅에 대하여 전체 전송 횟수와 타임 슬롯 이용률 관점에서 제안된 타부서치 알고리즘의 성능평가를 수행하였다. 성능평가 결과에서 제안된 타부서치 알고리즘은 이전에 제안된 다른 최적화 알고리즘보다 더 우수한 결과를 나타내었다.\n",
      "\n",
      "The broadcast scheduling problem based in the time division multiple access is a problem of designing that all nodes can transmit without collision using time slots. In this paper, we propose a broadcast scheduling optimization algorithm that maximizes the total number of transmissions and channel utilization by optimizing the transmission schedule of a node using broadcast in TDMA-based wireless mesh networks. The proposed optimization algorithm uses Tabu search as one of metaheuristic methods. The proposed Tabu search algorithm was used as an objective function to maximize the total number of transmissions, and the neighborhood generation method was efficiently designed. In this paper, performance evaluation of the proposed tabu search algorithm was performed in terms of the total number of transmissions and time slot utilization for all broadcasting occurring in the network. In the performance evaluation results, the proposed tabu search algorithm showed better results than other previously proposed optimization algorithms.\n",
      "\n",
      "EM 알고리즘을 이용한 기계부품의 고장 원인 및 신뢰성 분석\n",
      "직렬 시스템의 고장 원인은 대부분 내부 부품 고장에 의한 것이다. 부품별 고장 원인을 분석하기 위해 경쟁 위험모델을 적용한 경쟁 고장모드(CFM)를 사용한다. 기존 분석도구인 ReliaSoft에서의 CFM 계산은 기존의 수치해석법을 따른 것으로 판단이 된다. 본 논문에서는 이를 개선하기 위해서 EM 알고리즘을 이용한 경쟁 고장모드를 소개한다. 그리고 중단된 데이터가 포함된 고장모드를 지녔을 때와 3가지 고장모드를 지녔을 때의 실제 데이터를 통해 기존 분석도구 결과와 비교한다. 또한 신뢰도 측정치(신뢰도, 특성수명)를 ReliaSoft의 결과와 비교하였다. 제안하는 방법은 R 프로그램을 이용하여 쉽게 구현할 수 있다.\n",
      "\n",
      "Consider a system comprising multiple components connected in series. The failure of the whole system is caused by the earliest failure of any of the components; this is commonly referred to as the competing failure mode (CFM). It is also known as the competing risks model in the literature. Many analysis tools, such as ReliaSoft, include the CFM method; however, they do not provide a good fit compared with the EM algorithm method for CFMs. In this paper, we introduce CFMs using the EM algorithm. We applied real data examples with three failure modes to estimate the shape and scale parameters of the system. In addition, reliability measures (reliability and characteristic life) were compared with ReliaSoft results. The proposed method can be easily implemented using the developed R program.\n",
      "\n",
      "통계적 추정기 및 LPC 잔차잡음 억제에 기반한 음성강조 알고리즘의 SNR 효과\n",
      "음성에 잡음이 중첩된 경우에 음성에 대한 선형예측 정밀도가 감소하게 되어 재생된 음성의 품질이 떨어진다. 따라서 본 논문에서는 다양한 잡음이 포함된 음성신호에 대하여 통계적 추정기에 의해서 개선된 선형예측계수의 잔차신호를 사용하여 잡음제거를 목적으로 한 음성강조 알고리즘을 제안한다. 본 실험에서는 신호처리에 의한 SN비의 개선을 목적으로 하여 5종류의 배경잡음에 의하여 중첩된 음성신호를 사용하여 입력 SNR이 약 0㏈∼4㏈인 경우에 대하여 실험을 진행하였으며, 각 잡음이 중첩된 음성에 대하여 출력 SNR이 평균 4.99(㏈), 5.10(㏈), 5.14(㏈), 6.40(㏈), 6.59(㏈) 개선된 것을 알 수 있었다. 따라서 본 논문에서 제안한 알고리즘은 잡음억제의 SNR의 양호한 결과로부터 음성강조의 효과가 크다는 것을 명확히 할 수 있었다.\n",
      "\n",
      "When noise signal is included in speech, linear prediction accuracy for the speech is reduced, and thus the quality of the reproduced speech is degraded. Therefore, this paper proposes a speech enhancement algorithm for reducing the noise using the residual signal of the linear predictive coefficient improved by statistical estimator, for various noisy speech signals. In this experiment, for the purpose of improving the SNR by signal processing, this experiment was conducted for the case where the input SNRs are about 0㏈ to 4㏈ using noisy speech signal contaminated by 5 types of background noises. From these experiment results, it was confirmed that output SNRs improved by averages of 4.99(㏈), 5.10(㏈), 5.14(㏈), 6.40(㏈), and 6.59(㏈) for each noisy speech signal. Therefore, it was clarified that the proposed algorithm has a good effect of speech enhancement from the SNR noise reduction results.\n",
      "\n",
      "개인맞춤형 건강식생활 정보제공 알고리즘 개발을 위한 Q분석기법 활용 연구 : 대학생을 중심으로\n",
      "이 연구는 주제 관련 대학생들이 인식하는 개인맞춤형 건강식생활 정보제공 알고리즘 개발에 관한 주관성을 진단하고, 기능적인 측면에서 세부적인 유형적 효과요인들을 확인하여 향후 개선과 방향성을 알아보고자 하였다. 연구분석을 위해서 연구진에서는 Q방법론을 이용하였다. 분석된 결과, 총 5가지의 유형, 즉 유형Ⅰ[(n=7) : 식사 조절 정보 유형], 유형Ⅱ[(n=2) : 적정 음식 섭취 정보 유형], 유형Ⅲ[(n=3) : 선별적 음식 정보 유형], 유형Ⅳ[(n=2) : 인스턴트 제한 정보 유형], 유형Ⅴ[(n=1) : 건강증진식품 정보 유용성 유형] 등으로 분류되었다. 또한 QUANL 프로그램을 실시해 본 결과, 전체변량의 약 60(0.5993)%를 설명하였다. 결과적으로, 앞으로 계량적인 실증적 연구와 소비자들의 의견을 종합한 비교와 대안책이 추가된다면, 주제 관련 일반 소비자들의 주관성에 관한 보다 심도 있는 연구결과가 제시될 수 있을 것으로 예상된다. 또한, 이러한 연구의 한계를 보완하는 후속연구가 지속적으로 진행되어지기를 기대한다.\n",
      "\n",
      "This paper-work was carried out by practical method in a subjectivity study accessible in-depth, in getting out of past convention of technical quantity analysis on health-food-life information-providing in personal-target type through Q-analysis(QUANL program). The perception pattern come out in this study were divided into a five types, it is that is Ⅰ[(n=7) : meal control information type], Ⅱ[(n=2) : reasonable food intake-information type Ⅲ[(n=3) : selective food information type], Ⅳ[(n=2) : instant limited-information type], Ⅴ[(n=1) : health-promotion-food information usefulness type], and analysed in about 60(0.5993)% in cumulative result(explanation) side. There are a various ‘health-food-life’ images. In conclusion side, this study is to ascertain acceptance behavior about reception type on health-food-life information-providing in personal-target type through Q-analysis ; to propose a developmental suggestion about it.\n",
      "\n",
      "스마트시티 데이터허브를 활용한 공조시스템용 에너지소비량 절감 알고리즘 개발\n",
      "공기조화시스템은 건물 내 공기의 질을 이용자들의 활동에 쾌적하도록 유지해주는 기술 일체를 뜻한다. 대형 건축물의 중앙식 공조시스템은 미리 설계된 매뉴얼에 맞추어 단순하게 운영되기에, 건물에너지의 낭비를 초래하고, 실내 공기질 개선 등 이용자의 요구사항 반영에도 난점을 지닌다. 다양한 도시 데이터를 바탕으로 시민 삶의 질 향상을 목표로 하는 스마트시티와 데이터허브의 도입은 기존 공기조화시스템 개선의 동력이 될 수 있다. 본 논문은 페르소나 기법을 활용하여 테스트 건물인 서울대학교 시흥캠퍼스 교육협력동 이용자들의 니즈를 파악하고, 스마트시티 데이터허브의 데이터를 활용하는 공조시스템 실시간 운영 알고리즘을 제시한다. 알고리즘은 건물 내외 이산화탄소 농도, 미세먼지 농도, 온습도를 비교하여 공조시스템의 댐퍼 개도를 실시간으로 조절한다. 새로운 알고리즘은 공조시스템의 연간 에너지소비량을 기존 대비 32% 절감하고, 실내 미세먼지 및 이산화탄소 농도 또한 이용객의 쾌적 활동범위에서 유지한다.\n",
      "\n",
      "The HVAC system maintains the quality of air in the building to be comfortable for the inhabitants. As the HVAC system for large buildings has usually been operated manually, it has weaknesses in efficient use of energy and reflecting inhabitants’ needs such as air quality improvement. Development of smart city and data hubs, aimed at improving the quality of life of citizens based on various city data, can become a driving force in improving the conventional HVAC system. By using the persona technique, this paper identifies the needs of inhabitants of the test-bed building in Seoul National University and suggests algorithm that run the HVAC system in real-time using data collected through the smart city data hub. The algorithm is designed to adjust the damper position of the HVAC system real-time by comparing the levels of carbon dioxide, fine dust, and temperature and humidity inside and outside the building. Simulation results show that the new HVAC system saves 32% in annual energy consumption compared to the previous system and maintains the concentration of fine dust and carbon dioxide within the range of conditions that allow occupants to comfortably carry out activities.\n",
      "\n",
      "IQR알고리즘의 사분범위 조정을 활용한 당뇨 예측 방법\n",
      "본 논문에서는 당뇨병을 조기진단 및 예측하기 위해 머신러닝에 사용되는 당뇨데이터를 전처리하는 방법을 제안한다. 전처리 방법에는 의료데이터의 대표적인 문제인 결측치, 이상치, 클래스의 불균형문제를 포함하고 있다. 특히 이상치문제를 해결하기 위해 대표적으로 사용되는 IQR알고리즘은 데이터의 격차가 클 경우, 많은 양의 데이터를 이상치로 간주하기 때문에 본 논문에서는 기존의 IQR알고리즘이 아닌 알고리즘 내의 사분범위를 조정하여 입력데이터에 적합한 이상치제거 알고리즘을 제안하였다.결측치 및 클래스의 불균형 문제는 중앙값과 SMOTE알고리즘을 사용하여 문제를 해결하였다. 제안하는 전처리 방법을 사용하였을 경우, 기존의 이상치 알고리즘을 적용한 결과보다 5%의 우수한 성능을 나타내었으며, 또한 AUC수치 역시 4% 더 높은 성능을 보이고 있다.\n",
      "\n",
      "In this paper, a method of pretreatment of diabetes data used in machine learning is proposed to diagnose and predict diabetes early. The preprocessing methods include missing values, abnormal values, and level imbalance, which are representative problems in medical data. In particular, the IQR algorithm, which is used to solve the ideal value problem, considers a large amount of data as ideal value when the data gap is large, so this paper proposes an ideal value elimination algorithm suitable for input data. The median and SMOTE algorithms are used to solve the problem of missing values and grade imbalance. The proposed pretreatment method shows 5% better performance than the previous ideal value algorithm, and the AUC value is also 4%.\n",
      "\n",
      "남극 환경에서 다중 로봇 시스템을 위한 최근접 이웃 알고리즘 기반 효율적 다중 작업 스케줄링\n",
      "This paper addresses the problem of multi-robot task scheduling in Antarctic environments. It is difficult to operate multiple robots in Antarctic environments due to the icy ground condition and the lack of powers. In our previous work, the multi-robot task scheduling in Antarctic environments has been solved using ant colony optimization. Although it worked successfully, it caused much computation time. This paper proposes an efficient multi-robot task scheduling approach using nearest neighbor algorithm in Antarctic environments. The proposed method was tested in both simulated environments and Antarctic environments. The proposed method showed better performance in terms of computation time and cost than ant colony optimization and genetic algorithm.\n",
      "\n",
      "UAV 지원 Cellular-connected 시스템에서 Position Fingerprint Database를 이용한 협력적 빔 선택 알고리즘\n",
      "UAV (Unmanned Aerial Vehicle)는 높은 고도와 이동성의 특징 때문에, 지상 네트워크의 한계를 넘을 수 있어 NR (New Radio) 시스템의 핵심 요소로 주목받고 있다. 하지만 높은 고도의 UAV는 높은 LOS (Line-Of-Sight) 확률로 다른 셀 간 간섭의 영향을 크게 받을 수 있다. 이에 본 논문에서는 간섭의 영향을 줄이고, 전송 효율을 최대화할 수 있도록 최적의 빔을 선택하는 알고리즘을 제안한다. 제안 알고리즘은 크게 두 단계로 구성된다. 본 논문에서 제시한 사용자 타입에 맞게 필요한 정보를 저장하는 사용자 위치 기반 핑거프린트 데이터베이스 (Fingerprint Database)를 구축하는 과정과 협력적 빔 선택 과정으로 나뉜다. 성능 분석을 위해 셀룰러 협력 다운링크 시스템을 기반으로 모의실험을 진행하였고, 성능 분석 지표로는 신호 대 간섭 및 잡음 비율의 누적 분포 함수 (SINR CDF, Signal-to-Interference-plus-Noise Ratio Cumulative Distribution Function)와 스펙트럼 효율의 누적 분포 함수 (SE CDF, Spectral Efficiency Cumulative Distribution Function)를 사용하였다. 성능 분석 결과 제안 알고리즘이 간섭의 영향은 줄이고, 원하는 신호의 성능은 높인다는 점을 확인하였다. 또한, 정보 교환에 필요한 자원의 양을 줄임으로써 오버헤드 및 시스템의 비용을 고려한 효율적인 알고리즘이 될 수 있음을 확인하였다.\n",
      "\n",
      "Due to its high altitude and mobility characteristics, unmanned aerial vehicle (UAV) is attracting attention as a key element of new radio (NR) systems as they can exceed the limits of terrestrial networks. However, high line-of-sight (LOS) probability due to high altitude can be greatly affected by interference between different cells. Accordingly, this paper proposes an algorithm that select optimal beam to reduce the impact of interference, and maximize transmission efficiency. The proposed algorithm consists largely of two steps. According to the user type presented in this paper, it is divided into a process of constructing a user position-based fingerprint database and a process of cooperative beam selection process. Simulations were conducted based on cellular cooperative downlink systems for performance analysis, and signal-to-interference-plus-noise cumulative distribution function (SINR CDF) and spectral efficiency cumulative distribution function (SE CDF) were used as performance analysis indicators. As a result of performance analysis, it was confirmed that the proposed algorithm can reduce the effect of interference and increase the performance of the desired signal. Also, it was confirmed that it is an efficient algorithm that considers overhead and system costs by reducing the amount of resources required for information exchange.\n",
      "\n",
      "계산 광학 현미경: 알고리즘을 이용한 영상 복원 기술\n",
      "Like a mobile phone camera, optical microscopy typically relies on optical lenses that convert a plane wave to a spherical wave or vice versa. In such conventional imaging scheme, light from an object point propagates through a set of lenses and creates a tight focus on a camera, resulting in 1 to 1 relation between the object point and the camera pixel. Recently, this conventional imaging paradigm has been challenged by a new paradigm where computational algorithms replace the role of lenses. Here, I will introduce the concept of computational optics and some novel microscopy techniques based on algorithms.\n",
      "\n",
      "센서 데이터 기반의 타이어 상태진단 알고리즘 개발\n",
      "Purpose: Tire maintenance is essential for safety, as tire failure can cause significant damage to human health and infrastructure during light rail operations. Therefore, we developed a diagnostic algorithm for light rail rubber tires to prevent such catastrophic events.\n",
      "Methods: Vibration signals measured by tri-axis accelerometers were acquired during real-world light rail operation, and we compared vibrations among various tire states, established a health index, and developed a model for determining tire state.\n",
      "Results: The most important type of vibration in terms of tire state was x-axis vibration. Our model determined tire states by calculating x-axis vibration differences in various tire conditions. Furthermore, high model accuracy was confirmed by stratified k-fold cross-validation.\n",
      "Conclusion: Our diagnostic algorithm for determining tire condition reduces operating and support costs and promotes reliability and safety by enabling timely and appropriate maintenance that considers the age of individual tires. Thus, it could replace existing time-based maintenance protocols.\n",
      "\n",
      "Depth Camera와 GPS를 활용한 실시간 객체 좌표 생성 알고리즘 개발\n",
      "뎁스 카메라를 이용한 다양한 연구가 많이 발전하고 있다. 본 논문은 이러한 추세에 발맞춰 뎁스 카메라와 RGB 카메라를 동시에 이용하여 실시간 물체의 GPS UTM 좌표를 찾는 연구를 수행했다. 먼저 해상도가 다른 두 카메라의 해상도 매칭을 수행한 후, RGB 카메라와 인식된 물체의 경계 상자의 중앙 픽셀 좌표를 사용해 객체 인식을 한다. 그 후, 카메라로부터 객체까지의 거리를 같은 픽셀로 해상도를 맞춘 뎁스 카메라를 사용해 측정했다. 카메라 픽셀의 초점, 객체 경계 상자의 중심 픽셀 좌표, 뎁스 카메라로 구한 거리를 통해 카메라에서 객체까지의 X, Y 거리를 계산했다. 그런 다음 카메라와 같은 위치에 있는 GPS의 UTM 좌푯값, GPS의 이전 좌표를 통해 추출된 방향, 카메라가 얻은 객체로부터 떨어진 X, Y 거리 등을 계산해 계산된 값을 측정했다. 실험 결과의 정확성을 위해 GPS를 통해 특정 지점의 거리와 UTM 좌표를 미리 구한 뒤 실제 사람이 그 위치에 서서 객체를 인식뒤 정확도를 판단했다. 실험 결과, 10m 이내에서 높은 정확도의 결과를 얻었다.\n",
      "\n",
      "Various studies using depth cameras are developing a lot. In line with the trend, this paper conducted a study to find GPS UTM coordinates of real-time objects using a camera with a depth camera and an RGB camera at the same time. After first performing resolution matching of two cameras with different resolutions, we find out object recognition using RGB cameras and central pixel coordinates of the bounding box of the recognized object. After that, the distance from the camera to the object was measured using a depth camera that matched the resolution with the same pixel. X and Y distances away from the camera to the object were calculated through the focus of the camera pixel, the center pixel coordinates of the bounding box of the object, and the distance obtained by the depth camera. Then, the calculated value was calculated by the UTM coordinate value of GPS in the same position as the camera, the heading direction extracted through the previous coordinates of GPS, and the X and Y distances away from the object obtained by the camera. For the accuracy of the experimental results, the distance and UTM coordinates of a particular point were obtained in advance through GPS, and then a real person stood at the location and recognized the object, and then the accuracy was determined. As a result of the experiment, a result with high accuracy was obtained within 10m.\n",
      "\n",
      "고해상도 단순 이미지의 객체 분류 학습모델 구현을 위한 개선된 CNN 알고리즘 연구\n",
      "CNN(Convolutional Neural Network) 알고리즘은 인공신경망 구현에 활용되는 대표적인 알고리즘으로 기존 FNN(Fully connected multi layered Neural Network)의 문제점인 연산의 급격한 증가와 낮은 객체 인식률을 개선하였다. 그러나 IT 기기들의 급격한 발달로 최근 출시된 스마트폰 및 태블릿의 카메라에 촬영되는 이미지들의 최대 해상도는 108MP로 약 1억 8백만 화소이다. 특히 CNN 알고리즘은 고해상도의 단순 이미지를 학습 및 처리에 많은 비용과 시간이 요구된다. 이에 본 논문에서는 고해상도 단순 이미지의 객체 분류 학습모델 구현을 위한 개선된 CNN 알고리즘을 제안한다. 제안하는 알고리즘은 고해상도의 이미지들의 학습모델 생성 시간을 감소하기 위해 CNN 알고리즘의 풀링계층의 Max Pooling 알고리즘 연산을 위한 인접 행렬 값을 변경한다. 변경한 행렬 값마다 4MP, 8MP, 12MP의 고해상도 이미지들의 처리할 수 있는 학습 모델들을 구현한다. 성능평가 결과, 제안하는 알고리즘의 학습 모델의 생성 시간은 12MP 기준 약 36.26%의 감소하고, 학습 모델의 객체 분류 정확도와 손실률은 기존 모델 대비 약 1% 이내로 오차 범위 안에 포함되어 크게 문제가 되지 않는다. 향후 본 연구에서 사용된 학습 데이터보다 다양한 이미지 종류 및 실제 사진으로 학습 모델을 구현한 실질적인 검증이 필요하다.\n",
      "\n",
      "A convolutional neural network (CNN) is a representative algorithm for implementing artificial neural networks. CNNs have improved on the issues of rapid increase in calculation amount and low object classification rates, which are associated with a conventional multi-layered fully-connected neural network (FNN). However, because of the rapid development of IT devices, the maximum resolution of images captured by current smartphone and tablet cameras has reached 108 million pixels (MP). Specifically, a traditional CNN algorithm requires a significant cost and time to learn and process simple, high-resolution images. Therefore, this study proposes an improved CNN algorithm for implementing an object classification learning model for simple, high-resolution images. The proposed method alters the adjacency matrix value of the pooling layer\"s max pooling operation for the CNN algorithm to reduce the high-resolution image learning model\"s creation time. This study implemented a learning model capable of processing 4, 8, and 12 MP high-resolution images for each altered matrix value. The performance evaluation result showed that the creation time of the learning model implemented with the proposed algorithm decreased by 36.26% for 12 MP images. Compared to the conventional model, the proposed learning model\"s object recognition accuracy and loss rate were less than 1%, which is within the acceptable error range. Practical verification is necessary through future studies by implementing a learning model with more varied image types and a larger amount of image data than those used in this study.\n",
      "\n",
      "여론조사와 빅 데이터를 융합한 예측 알고리즘 개발과 선거적용에 관한 연구\n",
      "2016년 미국 대통령 선거에서 대부분의 미국 여론조사 기관들은 힐러리 클린턴이 오차범위 밖에서 당선될 것을 예측했으나 결과적으로 도널드 트럼프가 대통령으로 당선되었다. 최근 한국에서도 선거 여론조사 결과가 조사기관 사이에 차이가 커서 불신을 받고 있으며 이를 보완할 새로운 방법이 필요하다. 선거 여론조사가 불신을 받는 원인으로는 제한된 표본의 수, 다양한 데이터 수집방법, 특정한 연령구간에 응답이 부족할 때 사용하는 보정기법으로 추정된다. 이 연구에서는 여론조사 결과에 포털 서비스, 블로그, 트위터, 인스타그램 등에서 후보자를 언급한 버즈량을 시간을 변수로 가중치를 부가하여 결합하며 여기에 검색어와 댓글의 긍·부정 반응을 점수를 가감하는 후처리 기법으로 선거결과를 예측하는 알고리즘을 개발한다. 성능평가를 위해 개발된 알고리즘을 지난 한국 대통령 선거 4개월 동안에 적용한다. 선거운동 기간에는 바로 다음 주 여론조사를 예측하고 투표일에는 대통령 당선자와 득표율을 예측하고 오차를 기존의 여론조사들과 비교, 분석한다.\n",
      "\n",
      "A lot of polling organizations predicted Hillary Clinton would win in 2016 USA presidential election over margin of error, though as a result, Donald Trump won. In Republic of Korea supplementary method should be found as many people distrust the opinion polls due to large deviation errors across survey organizations. Limited number of samples, too diverse data acquisition methods and correction techniques for lack of data at a certain age are the likely causes. This research develops a algorithm combining two different data sets, not only opinion poll but also buzz data from Internet portal services, blogs, Twitter and Instagram. These two are combined with assigning weighted values based upon time parameter. To enhance prediction reliability, adjustment technique using positive-negative scoring through figuring out search words and comments in SNS was post-processed as well. To evaluate prediction accuracy it is evaluated during four month Korea presidential election campaign. The prediction results are compared to the next the week opinion poll during campaign. At vote day this predicted the president-elect, and prediction errors to actual votes are computed and analysed, finally.\n",
      "\n",
      "킥보드 불법 주차 문제 해결을 위한 도착지 중심 스테이션 증설 알고리즘\n",
      "본 연구는 공유 전동 킥보드 불법 주차 문제를 해결하고 서비스 품질을 개선하기 위하여 새로운 스테이션 선정 알고리즘을 제안하는 것을 목표로 한다. 최근 도시 교통 문제의 해결 방안으로 대중교통과 최종 목적지를 연결하는 퍼스트-라스트 마일 수단으로 공유 전동 킥보드가 주목받고 있다. 그에 따라 공유 전동 킥보드 시장도 급속도로 성장하면서 그로 인한 문제 또한 심화되고 있다. 이에 본 연구에서는 문제의 본질을 파악하기 위해 텍스트 데이터를 수집하여 ‘LDA 토픽 모델링’으로 공유 킥보드에 관한 이슈를 보행자와 이용자 관점에서 살펴보고 이를 바탕으로 스테이션 증설 알고리즘을 마련하려 한다. 기존에 이미 일부 주차장이 설치되어 있지만 기존의 주차장 위치는 실제 견인 다발 지역과 불일치한다. 따라서 본 연구에서는 ‘서울특별시 전동 킥보드 견인 현황’ 데이터와 여러요인을 반영하여 DBSCAN을 통한 1차 클러스터링 후, K-means를 적용하는 혼합형 클러스터링 기법으로 실제 견인 밀도가 높은 곳에 스테이션을 설치할 수 있는 알고리즘을 제안한다.\n",
      "\n",
      "In this paper, we propose a new station selection algorithm to solve the illegal parking problem of shared electric scooters and improve the service quality. Recently, as a solution to the urban transportation problem, shared electric scooters are attracting attention as the first and last mile means between public transportation and final destinations. As a result, the shared electric scooter market grew rapidly, problems caused by electric scooters are becoming serious. Therefore, in this study, text data are collected to understand the nature of the problem, and the problems related to shared scooters are viewed from the perspective of pedestrians and users in ‘LDA Topic Modeling’, and a station extension algorithm is based on this. Some parking lots have already been installed, but the existing parking lot location is different from the actual area of tow. Therefore, in this study, we propose an algorithm that can install stations at high actual tow density using mixed clustering technology using K-means after primary clustering by DBSCAN, reflecting the ‘current state of electric scooter tow in Seoul’.\n",
      "\n",
      "Levenshtein Distance를 활용한 문자열 유사도 기반의 BIM 속성정보 CFD 매칭 알고리즘\n",
      "For attribute data matching between BIM and CFD, this study proposed a BIM attribute information matching algorithm based on string similarity using levenshtein distance. Considering the versatility of BIM and CFD models, algorithms were developed for IFC and OpenFOAM, which are open-source technologies. The algorithm consists of three modules. First of all, BIM attribute data extraction algorithm was established to extract attribute information from BIM. In addition, in order to input CFD of accurate property information, a database of property information on building materials was established. To implement a matching algorithm based on string similarity, the levenshtein distance algorithm, which calculates the editing distance between two strings, was applied. A matching algorithm was designed to convert the edit distance to similarity and input the attribute data of the selected optimal material to the CFD model. The attribute data of the material with the highest degree of similarity was input into the CFD model. Validation of the developed algorithm was conducted to evaluate the accuracy. As a result of validation, the BIM attribute information extraction algorithm was evaluated with an accuracy of about 99.1%. The matching algorithm accurately matched all materials belonging to the IFC to the CFD model. Therefore, the accuracy of the algorithm proposed in this study was validated.\n",
      "\n",
      "CMA-ES/SPGD 이중 알고리즘을 통한 결맞음 빔 결합 시스템 위상제어 및 동작성능에 대한 전산모사 분석\n",
      "본 연구에서는 다채널 결맞음 빔결합 시스템을 위한 위상제어 방식으로 covariant matrix adaption evolution strategy (CMA-ES) 알고리즘 및 stochastic parallel gradient descent (SPGD) 알고리즘을 결합한 이중 위상제어 알고리즘을 제안하고 그 동작 특성을 전산모사를 통해 분석한다. 제안하는 CMA-ES/SPGD 이중 위상제어 알고리즘은 결합된 최종 출력광 세기가 미리 설정된 특정값에 도달하기 전까지는 그 위상제어 최적화를 CMA-ES 알고리즘을 통해 진행하고, 그 이후에는 SPGD 알고리즘으로 전환하여 진행하는 순차적 이중 구조를 취한다. 이를 이상적인 7채널과 19채널 광섬유 결합기 기반 결맞음 빔결함 시스템에 적용하였을 때, 위상제어 최적화 평균 수렴시간이 기존의 SPGD 알고리즘만 단독적용한 경우에 비해 약 10% 단축됨을 확인하였다. 뿐만 아니라, 동일한 결맞음 빔결함 시스템에서 실제 환경과 유사하게 각 채널광에 위상잡음을 부가적으로 인가한 경우, 본 연구에서 제안하는 이중 위상제어 알고리즘을 적용할 경우 주어진 조건에서 그 평균 수렴시간이 기존의 SPGD 알고리즘만 단독적용한 경우에 비해 7채널 시스템의 경우 약 17%, 19채널 시스템의 경우 약 16–27% 정도 단축됨을 확인하였다. 본 연구에서 제안한 CMA-ES/SPGD 이중 위상제어 알고리즘은 향후 실제 대기 환경과 같이 위상잡음 효과를 무시할 수 없는 조건에서 결맞음 빔결합을 구현시 매우 유용하게 활용될 수 있을 것으로 기대된다.\n",
      "\n",
      "In this study, we propose a hybrid phase-control algorithm for multi-channel coherent beam combining (CBC) system by combining the covariant matrix adaption evolution strategy (CMA-ES) and stochastic parallel gradient descent (SPGD) algorithms and analyze its operational performance. The proposed hybrid CMA-ES/SPGD algorithm is a sequential process which initially runs the CMA-ES algorithm until the combined final output intensity reaches a preset interim value, and then switches to running the SPGD algorithm to the end of the whole process. For ideal 7-channel and 19-channel all-fiber-based CBC systems, we have found that the mean convergence time can be reduced by about 10% in comparison with the case when the SPGD algorithm is implemented alone. Furthermore, we analyzed a more realistic situation in which some additional phase noise was introduced in the same CBC system. As a result, it is shown that the proposed algorithm reduces the mean convergence time by about 17% for a 7-channel CBC system and 16–27% for a 19-channel system compared to the existing SPGD alone algorithm. We expect that for implementing a CBC system in a real outdoor environment where phase noise cannot be ignored, the hybrid CMA-ES/SPGD algorithm proposed in this study will be exploited very usefully.\n",
      "\n",
      "세그멘테이션 기반 차선 인식 네트워크를 위한 적응형 키포인트 추출 알고리즘\n",
      "딥러닝 기반의 이미지 세그멘테이션은 차선 인식을 위해 널리 사용되는 접근 방식 중 하나로, 차선의 키포인트를 추출하기 위한 후처리 과정이 필요하다. 일반적으로 키포인트는 사용자가 지정한 임계값을 기준으로 추출한다. 하지만 최적의 임계값을 찾는 과정은 큰 노력을 요구하며, 데이터 세트(또는 이미지)마다 최적의 값이 다를 수 있다. 본 연구는 사용자의 직접 임계값 지정 대신, 대상의 이미지에 맞추어 적절한 임계값을 자동으로 설정하는 키포인트 추출 알고리즘을 제안한다. 본 논문의 키포인트 추출 알고리즘은 차선 영역과 배경의 명확한 구분을 위해 줄 단위 정규화를 사용한다. 그리고 커널 밀도 추정을 사용하여, 각 줄에서 각 차선의 키포인트를 추출한다. 제안하는 알고리즘은 TuSimple과 CULane 데이터 세트에 적용되었으며, 고정된 임계값 사용 대비 정확도 및 거리오차 측면에서 1.80%p와 17.27% 향상된 결과를 얻는 것을 확인하였다.\n",
      "\n",
      "Deep-learning-based image segmentation is one of the most widely employed lane detection approaches, and it requires a post-process for extracting the key points on the lanes. A general approach for key-point extraction is using a fixed threshold defined by a user. However, finding the best threshold is a manual process requiring much effort, and the best one can differ depending on the target data set (or an image). We propose a novel key-point extraction algorithm that automatically adapts to the target image without any manual threshold setting. In our adaptive key-point extraction algorithm, we propose a line-level normalization method to distinguish the lane region from the background clearly. Then, we extract a representative key point for each lane at a line (row of an image) using a kernel density estimation. To check the benefits of our approach, we applied our method to two lane-detection data sets, including TuSimple and CULane. As a result, our method achieved up to 1.80%p and 17.27% better results than using a fixed threshold in the perspectives of accuracy and distance error between the ground truth key-point and the predicted point.\n",
      "\n",
      "AI 기반 수요예측 알고리즘 모바일 모니터링 애플리케이션 설계\n",
      "최근 많은 기업이 다양한 AI 기반 수요예측 알고리즘을 통해서 이익을 창출하기 위해 시스템을 구축하고 있다. 그렇기에 본 연구에서는 AI 수요예측 관련 자료를 사용자가 실시간으로 모니터링 할 수 있는 애플리케이션을 개발하고자 한다. 이 애플리케이션을 만들 때 정보를 쉽게 이해하도록 색채를 용도에 맞춤으로써 도움을 줄 수 있고, 레이아웃을 고려하여 정보를 쉽게 전달하고 한눈에 알아볼 수 있도록 하는 것이 목표이다. 또한, 아이디와 비밀번호 확인, 고유 코드 부분 구성에서 체크 박스 기능과 각 텍스트 기능을 이용하여 설계하였다. 기업별로 정해진 고유 코드를 이용하여 해당되는 기업의 데이터만 확인할 수 있게끔 하여 기밀 데이터 보안성을 강화할 수 있다. 그로 인해 실시간 모니터링을 모바일 애플리케이션으로 보안 문제없이 볼 수 있다.\n",
      "\n",
      "Recently, many companies are building systems to generate profits through various AI-based demand forecasting algorithms. Therefore, this study aims to develop an application that allows users to monitor data related to AI demand prediction in real time. When creating this application, the goal is to help you easily understand the information by adapting the color to the purpose, and to easily convey the information and recognize it at a glance by considering the layout. In addition, the design was constructed using the check box function and each text function in the ID and password verification and the unique code partial configuration. Confidential data security can be enhanced by allowing only the data of the corresponding company to be checked using the unique code set for each company. As a result, real-time monitoring can be viewed without security problems with mobile applications.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(detail_url_list)):\n",
    "    print(title[i])\n",
    "    print(content[i])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "link_text = '3'\n",
    "\n",
    "browser.find_element(By.LINK_TEXT, link_text).click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
